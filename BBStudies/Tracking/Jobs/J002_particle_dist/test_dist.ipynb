{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import itertools\n",
    "import importlib\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# BOKEH\n",
    "import bokeh.plotting as bk\n",
    "import bokeh.models as bkmod\n",
    "import bokeh.layouts as bklay\n",
    "import bokeh.palettes as bkpalettes\n",
    "\n",
    "# xsuite\n",
    "import xtrack as xt\n",
    "import xmask as xm\n",
    "import xfields as xf\n",
    "import xpart as xp\n",
    "import xobjects as xo\n",
    "\n",
    "# BBStudies\n",
    "import BBStudies.Tracking.XsuitePlus as xPlus\n",
    "import BBStudies.Tracking.Utils as xutils\n",
    "import BBStudies.Physics.Constants as cst\n",
    "import BBStudies.Plotting.Bokeh.Tools as bktools\n",
    "import BBStudies.Plotting.Bokeh.Presets as bkpresets\n",
    "import BBStudies.Physics.Base as phys\n",
    "\n",
    "\n",
    "# ==================================================================================================\n",
    "# --- Functions to load collider with a given context\n",
    "# ==================================================================================================\n",
    "def load_collider(collider_path = '../001_configure_collider/zfruits/collider_001.json'):\n",
    "\n",
    "    collider = xt.Multiline.from_json(collider_path)\n",
    "    context = xo.ContextCpu(omp_num_threads='auto')\n",
    "\n",
    "    return collider,context\n",
    "\n",
    "\n",
    "\n",
    "# ==================================================================================================\n",
    "# --- Functions to plot resulting distribution\n",
    "# ==================================================================================================\n",
    "# Setting default values\n",
    "#=====================================\n",
    "_default_fig_width  = 1500\n",
    "_default_fig_height = 400\n",
    "\n",
    "_top_tab_height     = 300\n",
    "_bot_tab_height     = 500\n",
    "_default_fig_pad    = 100\n",
    "#=====================================\n",
    "\n",
    "def particles_to_HTML(particles,coordinates,collider,config,nemitt,rfbucket,export_path):\n",
    "\n",
    "    BOKEH_FIGS  = {}\n",
    "    \n",
    "    _default_fig_width  = 1800\n",
    "    _bot_tab_height     = 400\n",
    "    padding             = 20 \n",
    "    adjustment          = 0\n",
    "\n",
    "\n",
    "    # Normalized space\n",
    "    #=====================================\n",
    "    data = pd.DataFrame({'particle' :particles.particle_id,\n",
    "                         'x_sig'    :coordinates[0,:],\n",
    "                         'px_sig'   :coordinates[1,:],\n",
    "                         'y_sig'    :coordinates[2,:],\n",
    "                         'py_sig'   :coordinates[3,:],\n",
    "                         'zeta_sig' :coordinates[4,:],\n",
    "                         'pzeta_sig':coordinates[5,:]})\n",
    "\n",
    "    BOKEH_FIGS['n x-y'] = bkpresets.make_scatter_fig(data,xy=('x_sig','y_sig'),title='x-y norm. transv. space',width=int(_default_fig_width/4.5)+adjustment,height=_bot_tab_height,padding=0)\n",
    "    BOKEH_FIGS['n x-px'] = bkpresets.make_scatter_fig(data,xy=('x_sig','px_sig'),title='x norm. phase space',width=int(_default_fig_width/4.5),height=_bot_tab_height,padding=0)\n",
    "    BOKEH_FIGS['n y-py'] = bkpresets.make_scatter_fig(data,xy=('y_sig','py_sig'),title='y norm. phase space',width=int(_default_fig_width/4.5),height=_bot_tab_height,padding=0)\n",
    "    BOKEH_FIGS['n zeta-pzeta'] = bkpresets.make_scatter_fig(data,xy=('zeta_sig','pzeta_sig'),title='zeta norm. phase space',width=int(_default_fig_width/4.5),height=_bot_tab_height,padding=0)\n",
    "\n",
    "\n",
    "    BOKEH_FIGS['n x-px'].min_border_left  = padding\n",
    "    _lim = data.loc[:,data.columns[1:5]].abs().max().max()\n",
    "    _lim = np.ceil(1.1*_lim)\n",
    "    bktools.set_aspect(BOKEH_FIGS['n x-y']       , x_lim=(-_lim,_lim),y_lim=(-_lim,_lim), aspect=1, margin=padding-adjustment)\n",
    "    bktools.set_aspect(BOKEH_FIGS['n x-px']       , x_lim=(-_lim,_lim),y_lim=(-_lim,_lim), aspect=1, margin=0)\n",
    "    bktools.set_aspect(BOKEH_FIGS['n y-py']       , x_lim=(-_lim,_lim),y_lim=(-_lim,_lim), aspect=1, margin=0)\n",
    "\n",
    "    _lim = data.loc[:,data.columns[5:]].abs().max().max()\n",
    "    _lim = np.ceil(1.1*_lim)\n",
    "    bktools.set_aspect(BOKEH_FIGS['n zeta-pzeta'] , x_lim=(-_lim,_lim),y_lim=(-_lim,_lim), aspect=1, margin=0)\n",
    "\n",
    "    BOKEH_FIGS['n x-y'].xaxis.axis_label = r'$$\\tilde x /\\sqrt{\\varepsilon_{x}}$$'\n",
    "    BOKEH_FIGS['n x-y'].yaxis.axis_label = r'$$\\tilde y /\\sqrt{\\varepsilon_{x}}$$'\n",
    "\n",
    "    BOKEH_FIGS['n x-px'].xaxis.axis_label = r'$$\\tilde x /\\sqrt{\\varepsilon_{x}}$$'\n",
    "    BOKEH_FIGS['n x-px'].yaxis.axis_label = r'$$\\tilde p_x /\\sqrt{\\varepsilon_{x}}$$'\n",
    "\n",
    "    BOKEH_FIGS['n y-py'].xaxis.axis_label = r'$$\\tilde y /\\sqrt{\\varepsilon_{y}}$$'\n",
    "    BOKEH_FIGS['n y-py'].yaxis.axis_label = r'$$\\tilde p_y /\\sqrt{\\varepsilon_{y}}$$'\n",
    "\n",
    "    BOKEH_FIGS['n zeta-pzeta'].xaxis.axis_label = r'$$\\tilde \\zeta /\\sqrt{\\varepsilon_{\\zeta}}$$'\n",
    "    BOKEH_FIGS['n zeta-pzeta'].yaxis.axis_label = r'$$\\tilde p_\\zeta /\\sqrt{\\varepsilon_{\\zeta}}$$'\n",
    "\n",
    "\n",
    "    norm_qp = bklay.gridplot([[BOKEH_FIGS['n x-y'],BOKEH_FIGS['n x-px'] ,BOKEH_FIGS['n y-py'] ,BOKEH_FIGS['n zeta-pzeta']]],toolbar_location='right')\n",
    "    #=====================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # REAL SPACE\n",
    "    #=====================================\n",
    "    data = pd.DataFrame({'particle':particles.particle_id,'x':particles.x,'px':particles.px,'y':particles.y,'py':particles.py,'zeta':particles.zeta,'pzeta':particles.pzeta})\n",
    "\n",
    "    \n",
    "    BOKEH_FIGS['x-y']       = bkpresets.make_scatter_fig(data,xy=('x','y'),title='x-y transv. space',width=int(_default_fig_width/4.5)+adjustment,height=_bot_tab_height,padding=0)\n",
    "    BOKEH_FIGS['x-px']      = bkpresets.make_scatter_fig(data,xy=('x','px'),title='x phase space',width=int(_default_fig_width/4.5),height=_bot_tab_height,padding=0)\n",
    "    BOKEH_FIGS['y-py']      = bkpresets.make_scatter_fig(data,xy=('y','py'),title='y phase space',width=int(_default_fig_width/4.5),height=_bot_tab_height,padding=0)\n",
    "    BOKEH_FIGS['zeta-pzeta']= bkpresets.make_scatter_fig(data,xy=('zeta','pzeta'),title='zeta phase space',width=int(_default_fig_width/4.5),height=_bot_tab_height,padding=0)\n",
    "    BOKEH_FIGS['x-px'].min_border_left  = padding\n",
    "\n",
    "    # Custom JavaScript to format tick values   \n",
    "    chatGPT_tick = bkmod.FuncTickFormatter(code=\"\"\"\n",
    "                                                    function roundToSignificantDigits(num, n) {\n",
    "                                                        if(num == 0) {\n",
    "                                                            return 0;\n",
    "                                                        }\n",
    "                                                        var d = Math.ceil(Math.log10(num < 0 ? -num: num));\n",
    "                                                        var power = n - d;\n",
    "                                                        var magnitude = Math.pow(10, power);\n",
    "                                                        var shifted = Math.round(num * magnitude);\n",
    "                                                        return shifted / magnitude;\n",
    "                                                    }\n",
    "                                                    var roundedTick = roundToSignificantDigits(tick, 3); // Adjust '3' to your preferred number of significant digits\n",
    "                                                    return roundedTick.toExponential();\n",
    "                                                \"\"\")\n",
    "\n",
    "    BOKEH_FIGS['x-y'].xaxis.axis_label = r'$$x$$'\n",
    "    BOKEH_FIGS['x-y'].yaxis.axis_label = r'$$y$$'\n",
    "\n",
    "    BOKEH_FIGS['x-px'].xaxis.axis_label = r'$$x$$'\n",
    "    BOKEH_FIGS['x-px'].yaxis.axis_label = r'$$p_x$$'\n",
    "\n",
    "    BOKEH_FIGS['y-py'].xaxis.axis_label = r'$$y$$'\n",
    "    BOKEH_FIGS['y-py'].yaxis.axis_label = r'$$p_y$$'\n",
    "\n",
    "    BOKEH_FIGS['zeta-pzeta'].xaxis.axis_label = r'$$\\zeta$$'\n",
    "    BOKEH_FIGS['zeta-pzeta'].yaxis.axis_label = r'$$p_\\zeta$$'\n",
    "\n",
    "    BOKEH_FIGS['x-y'].xaxis.formatter = chatGPT_tick\n",
    "    BOKEH_FIGS['x-px'].xaxis.formatter = chatGPT_tick\n",
    "    BOKEH_FIGS['y-py'].xaxis.formatter = chatGPT_tick\n",
    "    BOKEH_FIGS['zeta-pzeta'].xaxis.formatter = chatGPT_tick\n",
    "    BOKEH_FIGS['x-y'].yaxis.formatter = chatGPT_tick\n",
    "    BOKEH_FIGS['x-px'].yaxis.formatter = chatGPT_tick\n",
    "    BOKEH_FIGS['y-py'].yaxis.formatter = chatGPT_tick\n",
    "    BOKEH_FIGS['zeta-pzeta'].yaxis.formatter = chatGPT_tick\n",
    "\n",
    "\n",
    "    color = 'mediumvioletred'\n",
    "    ls    = 'solid'\n",
    "    label = f'RF Bucket'\n",
    "\n",
    "    config_J001 = collider.metadata['config_J001']\n",
    "    sigma_z     = config_J001['config_collider']['config_beambeam'][f'sigma_z']\n",
    "\n",
    "    for zcut in list(np.linspace(0.001,rfbucket.zeta_max,10)) + [sigma_z,2*sigma_z,3*sigma_z]:\n",
    "        zeta_vec,delta_vec = rfbucket.invariant(zcut,npoints = 1000)\n",
    "\n",
    "        if zcut/sigma_z in [1,2,3]:\n",
    "            color = 'black'\n",
    "            ls    = 'dotted'\n",
    "            label = f'Ïƒ'\n",
    "        \n",
    "        line_top = BOKEH_FIGS['zeta-pzeta'].line(x=zeta_vec,y=delta_vec, line_width=4, color=color, alpha=0.4, line_dash=ls, legend_label=label)\n",
    "        line_bot = BOKEH_FIGS['zeta-pzeta'].line(x=zeta_vec,y=-delta_vec, line_width=4, color=color, alpha=0.4, line_dash=ls, legend_label=label)\n",
    "        line_top.level = 'overlay'\n",
    "        line_bot.level = 'overlay'\n",
    "\n",
    "\n",
    "    qp = bklay.gridplot([[BOKEH_FIGS['x-y'],BOKEH_FIGS['x-px'] ,BOKEH_FIGS['y-py'] ,BOKEH_FIGS['zeta-pzeta']]],toolbar_location='right')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # IMPORTING COLLIDER\n",
    "    # Importing Twiss\n",
    "    #-------------------------------------\n",
    "    twiss = {}\n",
    "    twiss['lhcb1'] = collider['lhcb1'].twiss().to_pandas()\n",
    "    twiss['lhcb2'] = collider['lhcb2'].twiss().reverse().to_pandas()\n",
    "    #-------------------------------------\n",
    "\n",
    "\n",
    "    # Filtering twiss to get rid of slices, entries and exits\n",
    "    #-------------------------------------\n",
    "    light_twiss = {}\n",
    "    for sequence in ['lhcb1','lhcb2']:\n",
    "        light_twiss[sequence] = xPlus.filter_twiss(twiss[sequence].set_index('name'),entries=['drift','..','_entry','_exit']).reset_index()\n",
    "    #-------------------------------------\n",
    "\n",
    "\n",
    "    # Making figures\n",
    "    #-------------------------------------\n",
    "    BOKEH_FIGS = {}\n",
    "    BOKEH_FIGS['twiss']   =  bkpresets.make_Twiss_Fig(collider,light_twiss,width=_default_fig_width,height=_default_fig_height,\n",
    "                                                    twiss_columns=['x','y','px','py','betx','bety','alfx','alfy','dx','dy','dpx','dpy','mux','muy'])\n",
    "    BOKEH_FIGS['lattice'] =  bkpresets.make_LHC_Layout_Fig(collider,twiss,width=_default_fig_width,height=_default_fig_height)\n",
    "    #-------------------------------------\n",
    "\n",
    "    # Setting up axes\n",
    "    #-------------------------------------\n",
    "    BOKEH_FIGS['lattice'].xaxis[1].visible = False\n",
    "    BOKEH_FIGS['twiss'].x_range = BOKEH_FIGS['lattice'].x_range\n",
    "    BOKEH_FIGS['lattice'].min_border_left  = padding\n",
    "    BOKEH_FIGS['twiss'].min_border_left    = padding\n",
    "\n",
    "    # grid_collider = bklay.gridplot([[BOKEH_FIGS['lattice']],[BOKEH_FIGS['twiss']]],toolbar_location='right')\n",
    "    grid_collider = bklay.column(BOKEH_FIGS['lattice'],BOKEH_FIGS['twiss'])\n",
    "    #-------------------------------------\n",
    "\n",
    "\n",
    "    # Adding info\n",
    "    #=====================================\n",
    "    metadata = {'Name'                  : config['particles']['name'],\n",
    "                'Number of particles'   : f'{len(particles.x):,}',\n",
    "                'Distribution type'     : config['particles']['type'],\n",
    "                'nemitt_x'              : f'{nemitt[0]:.3e}',\n",
    "                'nemitt_y'              : f'{nemitt[1]:.3e}',\n",
    "                'nemitt_zeta'           : f'{nemitt[2]:.3e}',\n",
    "                '--------------------'  : '--------------------',\n",
    "                'Collider' : Path(config['collider']['path']).stem,\n",
    "                'Sequence' : config['collider']['sequence'],\n",
    "                'Cycle at' : config['collider']['cycle_at'],\n",
    "                }\n",
    "    info = bktools.dict_to_HTML(metadata, header_text=\"Particles Info\", header_margin_top=20, header_margin_bottom=0,margin=20,indent= 2,nested_scale = 0.98, max_width = _default_fig_width)\n",
    "    #=====================================\n",
    "\n",
    "    # Adding collider config\n",
    "    #=====================================\n",
    "    config_list = {}\n",
    "    for key in collider.metadata.keys():\n",
    "        _info = bktools.dict_to_HTML(collider.metadata[key], header_text=key, header_margin_top=20, header_margin_bottom=0,margin=20,indent= 2,nested_scale = 0.98, max_width = _default_fig_width)\n",
    "        config_list[key] = _info\n",
    "    #=====================================\n",
    "\n",
    "\n",
    "    # Final layout\n",
    "    #=====================================\n",
    "    tab_margin = 20\n",
    "    bottom_tabs = bkmod.Tabs(tabs=[bkmod.TabPanel(child=info, title=\"Info\")])\n",
    "    bottom_tabs = bkmod.Row(bottom_tabs, margin=(0,0,0,tab_margin))\n",
    "\n",
    "    top_tabs = bkmod.Tabs(tabs=[bkmod.TabPanel(child=norm_qp, title=\"Norm. Phase Space\"),\n",
    "                                bkmod.TabPanel(child= qp    , title=\"Phys. Phase Space\")])\n",
    "    top_tabs = bkmod.Row(top_tabs, margin=(0,0,0,tab_margin))\n",
    "\n",
    "    tab_margin  = 0\n",
    "    global_tabs = bkmod.Tabs(tabs=[ bkmod.TabPanel(child=bklay.column(top_tabs,bottom_tabs), title=\"Particles\"),\n",
    "                                    bkmod.TabPanel(child=grid_collider, title=\"Collider Object\")] + \\\n",
    "                                  [ bkmod.TabPanel(child=config_list[key], title=key) for key in config_list.keys()])\n",
    "    global_tabs = bkmod.Row(global_tabs, margin=(tab_margin,tab_margin,tab_margin,tab_margin))\n",
    "    HTML_LAYOUT = global_tabs\n",
    "    #=====================================\n",
    "\n",
    "\n",
    "\n",
    "    # Setting font size\n",
    "    for _fig in BOKEH_FIGS.values():\n",
    "        _fig.xaxis.axis_label_text_font_size = \"15px\"\n",
    "        _fig.yaxis.axis_label_text_font_size = \"15px\"\n",
    "\n",
    "    # Exporting to HTML\n",
    "    #=====================================\n",
    "    bktools.export_HTML(HTML_LAYOUT,export_path,f'Particles - {metadata[\"Name\"]}')\n",
    "    #=====================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==================================================================================================\n",
    "# --- Main function\n",
    "# ==================================================================================================\n",
    "def particle_dist(config = None,config_path = 'config.yaml'):\n",
    "\n",
    "    # Loading config\n",
    "    #==============================\n",
    "    if config is None:\n",
    "        config = xutils.read_YAML(config_path)\n",
    "    #==============================\n",
    "\n",
    "    # Preparing output folder\n",
    "    #==============================\n",
    "    for _path in [config['particles']['path']]:\n",
    "        if _path is not None:\n",
    "            xutils.mkdir(_path) \n",
    "    #==============================\n",
    "\n",
    "\n",
    "\n",
    "    # LOADING COLLIDER\n",
    "    #==============================\n",
    "    print('LOADING COLLIDER')\n",
    "    sequence        = config['collider']['sequence']\n",
    "    ee_at_dict      = config['elements'][sequence]\n",
    "    collider,context = load_collider(collider_path = config['collider']['path'])\n",
    "\n",
    "\n",
    "    # Cycling line at_element\n",
    "    line    = collider[sequence]\n",
    "    cycle_at= config['collider']['cycle_at']\n",
    "    if line.element_names[0] != ee_at_dict[cycle_at]:\n",
    "        print('CYCLING LINE') \n",
    "        line.cycle(name_first_element=ee_at_dict[cycle_at], inplace=True)\n",
    "\n",
    "    # Building tracker\n",
    "    line.build_tracker(_context=context)\n",
    "    #==============================\n",
    "\n",
    "\n",
    "    # Parsing emittance\n",
    "    #==============================\n",
    "    # Extracting emittance from previous config\n",
    "    config_J001 = collider.metadata['config_J001']\n",
    "\n",
    "    nemitt_x,nemitt_y = (config_J001['config_collider']['config_beambeam'][f'nemitt_{plane}'] for plane in ['x','y'])\n",
    "    sigma_z           = config_J001['config_collider']['config_beambeam'][f'sigma_z']\n",
    "\n",
    "    # # Computing RF bucket emittance\n",
    "    rfbucket    = xPlus.RFBucket(line)\n",
    "    # nemitt_zeta = 2*1e-2*rfbucket.compute_emittance(sigma_z=sigma_z)\n",
    "    _twiss = line.twiss(method='6d')\n",
    "    twiss_init = _twiss.get_twiss_init(at_element=ee_at_dict[cycle_at])\n",
    "    co_dict    = twiss_init.particle_on_co.copy(_context=xo.context_default).to_dict()\n",
    "    WW      = twiss_init.W_matrix\n",
    "    betzeta = WW[4, 4]**2 + WW[4, 5]**2\n",
    "    nemitt_zeta = ((sigma_z**2/betzeta) * (co_dict['beta0'] * co_dict['gamma0']))[0]\n",
    "    #==============================\n",
    "\n",
    "    # Generating particles\n",
    "    #==============================\n",
    "    num_particles = config['particles']['num_particles']\n",
    "    mtd_config = config[config['particles']['type']]\n",
    "\n",
    "    # HYPERSPHERE\n",
    "    #==============================\n",
    "    if config['particles']['type'] == 'hypersphere':\n",
    "        coordinates = phys.hypersphere( N       = num_particles, \n",
    "                                        D       = 6, \n",
    "                                        r       = [ mtd_config['rx_sig'],\n",
    "                                                    mtd_config['rx_sig'],\n",
    "                                                    mtd_config['ry_sig'],\n",
    "                                                    mtd_config['ry_sig'],\n",
    "                                                    1.5*mtd_config['rzeta_sig'],\n",
    "                                                    mtd_config['rzeta_sig']], \n",
    "                                        seed    = mtd_config['seed'], \n",
    "                                        unpack  = True)\n",
    "    \n",
    "    # GRID\n",
    "    #==============================\n",
    "    elif config['particles']['type'] == 'grid':\n",
    "        grid_size = int(np.floor(np.sqrt(num_particles)))\n",
    "        x,y = np.meshgrid(  mtd_config['offset_x']+np.linspace(0,mtd_config['max_x'],grid_size),\n",
    "                            mtd_config['offset_y']+np.linspace(0,mtd_config['max_y'],grid_size))\n",
    "        \n",
    "        num_particles = len(x.flatten())\n",
    "        coordinates = np.array([x.flatten(),\n",
    "                                np.zeros(num_particles),\n",
    "                                y.flatten(),\n",
    "                                np.zeros(num_particles),\n",
    "                                mtd_config['zeta']*np.ones(num_particles),\n",
    "                                np.zeros(num_particles)])\n",
    "    #==============================\n",
    "\n",
    "                    \n",
    "        \n",
    "    \n",
    "    # Generating xsuite particles\n",
    "    particles = xp.build_particles( line        = line,\n",
    "                                    x_norm      = coordinates[0,:],\n",
    "                                    px_norm     = coordinates[1,:],\n",
    "                                    y_norm      = coordinates[2,:],\n",
    "                                    py_norm     = coordinates[3,:],\n",
    "                                    zeta_norm   = coordinates[4,:],\n",
    "                                    pzeta_norm  = coordinates[5,:],\n",
    "                                    nemitt_x    = nemitt_x, \n",
    "                                    nemitt_y    = nemitt_y,\n",
    "                                    nemitt_zeta = nemitt_zeta,\n",
    "                                    _context    = context)\n",
    "    \n",
    "    # Going back to normalized:\n",
    "    XX_sig = xPlus._W_phys2norm(particles.x,particles.px,particles.y,particles.py,particles.zeta,particles.pzeta, \n",
    "                                W_matrix    = twiss_init.W_matrix,\n",
    "                                co_dict     = twiss_init.particle_on_co.copy(_context=xo.context_default).to_dict(), \n",
    "                                nemitt_x    = nemitt_x, \n",
    "                                nemitt_y    = nemitt_y, \n",
    "                                nemitt_zeta = nemitt_zeta)\n",
    "    \n",
    "    # Checking:\n",
    "    assert np.allclose(XX_sig[0,:],coordinates[0,:],atol=1e-13, rtol=0), 'Error in x'\n",
    "    assert np.allclose(XX_sig[1,:],coordinates[1,:],atol=1e-13, rtol=0), 'Error in px'\n",
    "    assert np.allclose(XX_sig[2,:],coordinates[2,:],atol=1e-13, rtol=0), 'Error in y'\n",
    "    assert np.allclose(XX_sig[3,:],coordinates[3,:],atol=1e-13, rtol=0), 'Error in py'\n",
    "    assert np.allclose(XX_sig[4,:],coordinates[4,:],atol=1e-13, rtol=0), 'Error in zeta'\n",
    "    assert np.allclose(XX_sig[5,:],coordinates[5,:],atol=1e-13, rtol=0), 'Error in pzeta'\n",
    "\n",
    "\n",
    "    # Exporting\n",
    "    export_path = config['particles']['path'] + f'/{config[\"particles\"][\"name\"]}.parquet'\n",
    "    data = pd.DataFrame({'particle':particles.particle_id,  'x'     : particles.x,\n",
    "                                                            'px'    : particles.px,\n",
    "                                                            'y'     : particles.y,\n",
    "                                                            'py'    : particles.py,\n",
    "                                                            'zeta'  : particles.zeta,\n",
    "                                                            'pzeta' : particles.pzeta,\n",
    "                                                            'x_norm'    : coordinates[0,:],\n",
    "                                                            'px_norm'   : coordinates[1,:],\n",
    "                                                            'y_norm'    : coordinates[2,:],\n",
    "                                                            'py_norm'   : coordinates[3,:],\n",
    "                                                            'zeta_norm' : coordinates[4,:],\n",
    "                                                            'pzeta_norm': coordinates[5,:],\n",
    "                                                            })\n",
    "    data.to_parquet(export_path)\n",
    "\n",
    "\n",
    "    # Plotting:\n",
    "    export_path = config['particles']['path'] + f'/VIEWER_{config[\"particles\"][\"name\"]}.html'\n",
    "    particles_to_HTML(particles,coordinates,collider,config,[nemitt_x,nemitt_y,nemitt_zeta],rfbucket,export_path)\n",
    "    #==============================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return particles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config = None\n",
    "config_path = 'config.yaml'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING COLLIDER\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93820c795dbc4ecd913fd90325bb3635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading line from dict:   0%|          | 0/81116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading line from dict.           \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6917ba8333cf4714b4a341eca1d8ddbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading line from dict:   0%|          | 0/81260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading line from dict.           \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0aa125e1b64798a08e01e6288fd756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading line from dict:   0%|          | 0/80692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading line from dict.           \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275ca4b059e94152b7c8b2dc111b6dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading line from dict:   0%|          | 0/80836 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading line from dict.           \n",
      "Compiling ContextCpu kernels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1544d8b6441449ada8e152b6913efafb.c:13591:12: warning: variable 'gamma' set but not used [-Wunused-but-set-variable]\n",
      "    double gamma          = energy / m0;     // [1]\n",
      "           ^\n",
      "1544d8b6441449ada8e152b6913efafb.c:13859:9: warning: variable 'i' set but not used [-Wunused-but-set-variable]\n",
      "    int i=0;\n",
      "        ^\n",
      "1544d8b6441449ada8e152b6913efafb.c:13948:62: warning: variable 'ps_e_prime' set but not used [-Wunused-but-set-variable]\n",
      "    double e_e_prime, px_e_prime, py_e_prime, pzeta_e_prime, ps_e_prime, pt_e_prime;  // [GeV, 1, 1, 1, 1, 1] scattered primary\n",
      "                                                             ^\n",
      "1544d8b6441449ada8e152b6913efafb.c:13951:12: warning: unused variable 'e_loss_primary_tot' [-Wunused-variable]\n",
      "    double e_loss_primary_tot = 0.0;  // [GeV] total energy lost by the macroparticle\n",
      "           ^\n",
      "1544d8b6441449ada8e152b6913efafb.c:14204:21: warning: variable 'lumi_table_index' set but not used [-Wunused-but-set-variable]\n",
      "        RecordIndex lumi_table_index               = NULL;\n",
      "                    ^\n",
      "1544d8b6441449ada8e152b6913efafb.c:14115:18: warning: unused variable 'pzeta_slice_star' [-Wunused-variable]\n",
      "    const double pzeta_slice_star = BeamBeamBiGaussian3DData_get_slices_other_beam_pzeta_center_star(el, i_slice);\n",
      "                 ^\n",
      "6 warnings generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done compiling ContextCpu kernels.\n",
      "SingleRFHarmonicMatcher: Gaussian parameter is equal to 0.090m to achieve target RMS bunch length (0.090m).\n",
      "SingleRFHarmonicMatcher: Done transforming distribution. \n",
      "SingleRFHarmonicMatcher: Sampled 100 particles321%  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/hpn77ycx7h50r6rt81q7lghr0000gn/T/ipykernel_47021/2048831324.py:106: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  norm_qp = bklay.gridplot([[BOKEH_FIGS['n x-y'],BOKEH_FIGS['n x-px'] ,BOKEH_FIGS['n y-py'] ,BOKEH_FIGS['n zeta-pzeta']]],toolbar_location='right')\n",
      "/var/folders/yf/hpn77ycx7h50r6rt81q7lghr0000gn/T/ipykernel_47021/2048831324.py:106: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  norm_qp = bklay.gridplot([[BOKEH_FIGS['n x-y'],BOKEH_FIGS['n x-px'] ,BOKEH_FIGS['n y-py'] ,BOKEH_FIGS['n zeta-pzeta']]],toolbar_location='right')\n",
      "BokehDeprecationWarning: 'FuncTickFormatter' was deprecated in Bokeh 3.0.0 and will be removed, use 'CustomJSTickFormatter' instead.\n",
      "/var/folders/yf/hpn77ycx7h50r6rt81q7lghr0000gn/T/ipykernel_47021/2048831324.py:182: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  qp = bklay.gridplot([[BOKEH_FIGS['x-y'],BOKEH_FIGS['x-px'] ,BOKEH_FIGS['y-py'] ,BOKEH_FIGS['zeta-pzeta']]],toolbar_location='right')\n",
      "/var/folders/yf/hpn77ycx7h50r6rt81q7lghr0000gn/T/ipykernel_47021/2048831324.py:182: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  qp = bklay.gridplot([[BOKEH_FIGS['x-y'],BOKEH_FIGS['x-px'] ,BOKEH_FIGS['y-py'] ,BOKEH_FIGS['zeta-pzeta']]],toolbar_location='right')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling ContextCpu kernels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8f1ba7ef04c141e1a8a10ae9c5cf8190.c:5366:11: warning: '_GNU_SOURCE' macro redefined [-Wmacro-redefined]\n",
      "#  define _GNU_SOURCE // enable GNU libc NAN extension if possible\n",
      "          ^\n",
      "/Users/pbelanger/ABPLocal/BBStudies/Executables/miniforge3/envs/py-BB/include/python3.10/pyconfig.h:1621:9: note: previous definition is here\n",
      "#define _GNU_SOURCE 1\n",
      "        ^\n",
      "8f1ba7ef04c141e1a8a10ae9c5cf8190.c:18176:12: warning: variable 'gamma' set but not used [-Wunused-but-set-variable]\n",
      "    double gamma          = energy / m0;     // [1]\n",
      "           ^\n",
      "8f1ba7ef04c141e1a8a10ae9c5cf8190.c:18444:9: warning: variable 'i' set but not used [-Wunused-but-set-variable]\n",
      "    int i=0;\n",
      "        ^\n",
      "8f1ba7ef04c141e1a8a10ae9c5cf8190.c:18533:62: warning: variable 'ps_e_prime' set but not used [-Wunused-but-set-variable]\n",
      "    double e_e_prime, px_e_prime, py_e_prime, pzeta_e_prime, ps_e_prime, pt_e_prime;  // [GeV, 1, 1, 1, 1, 1] scattered primary\n",
      "                                                             ^\n",
      "8f1ba7ef04c141e1a8a10ae9c5cf8190.c:18536:12: warning: unused variable 'e_loss_primary_tot' [-Wunused-variable]\n",
      "    double e_loss_primary_tot = 0.0;  // [GeV] total energy lost by the macroparticle\n",
      "           ^\n",
      "8f1ba7ef04c141e1a8a10ae9c5cf8190.c:18789:21: warning: variable 'lumi_table_index' set but not used [-Wunused-but-set-variable]\n",
      "        RecordIndex lumi_table_index               = NULL;\n",
      "                    ^\n",
      "8f1ba7ef04c141e1a8a10ae9c5cf8190.c:18700:18: warning: unused variable 'pzeta_slice_star' [-Wunused-variable]\n",
      "    const double pzeta_slice_star = BeamBeamBiGaussian3DData_get_slices_other_beam_pzeta_center_star(el, i_slice);\n",
      "                 ^\n",
      "7 warnings generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done compiling ContextCpu kernels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pbelanger/ABPLocal/BBStudies/BBStudies/Plotting/Bokeh/Tools.py:360: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  gamma0 = 1/np.sqrt(1-ee_bb.beta0**2)\n",
      "/Users/pbelanger/ABPLocal/BBStudies/BBStudies/Plotting/Bokeh/Tools.py:360: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  gamma0 = 1/np.sqrt(1-ee_bb.beta0**2)\n",
      "/Users/pbelanger/ABPLocal/BBStudies/BBStudies/Plotting/Bokeh/Tools.py:360: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  gamma0 = 1/np.sqrt(1-ee_bb.beta0**2)\n",
      "/Users/pbelanger/ABPLocal/BBStudies/BBStudies/Plotting/Bokeh/Tools.py:360: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  gamma0 = 1/np.sqrt(1-ee_bb.beta0**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Particles - HYPERSPHERE:./particles/VIEWER_HYPERSPHERE.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading config\n",
    "#==============================\n",
    "if config is None:\n",
    "    config = xutils.read_YAML(config_path)\n",
    "#==============================\n",
    "\n",
    "# Preparing output folder\n",
    "#==============================\n",
    "for _path in [config['particles']['path']]:\n",
    "    if _path is not None:\n",
    "        xutils.mkdir(_path) \n",
    "#==============================\n",
    "\n",
    "\n",
    "\n",
    "# LOADING COLLIDER\n",
    "#==============================\n",
    "print('LOADING COLLIDER')\n",
    "sequence        = config['collider']['sequence']\n",
    "ee_at_dict      = config['elements'][sequence]\n",
    "collider,context = load_collider(collider_path = config['collider']['path'])\n",
    "\n",
    "\n",
    "# Cycling line at_element\n",
    "line    = collider[sequence]\n",
    "cycle_at= config['collider']['cycle_at']\n",
    "if line.element_names[0] != ee_at_dict[cycle_at]:\n",
    "    print('CYCLING LINE') \n",
    "    line.cycle(name_first_element=ee_at_dict[cycle_at], inplace=True)\n",
    "\n",
    "# Building tracker\n",
    "line.build_tracker(_context=context)\n",
    "#==============================\n",
    "\n",
    "\n",
    "# Parsing emittance\n",
    "#==============================\n",
    "# Extracting emittance from previous config\n",
    "config_J001 = collider.metadata['config_J001']\n",
    "\n",
    "nemitt_x,nemitt_y = (config_J001['config_collider']['config_beambeam'][f'nemitt_{plane}'] for plane in ['x','y'])\n",
    "sigma_z           = config_J001['config_collider']['config_beambeam'][f'sigma_z']\n",
    "\n",
    "# # Computing RF bucket emittance\n",
    "rfbucket    = xPlus.RFBucket(line)\n",
    "# nemitt_zeta = 2*1e-2*rfbucket.compute_emittance(sigma_z=sigma_z)\n",
    "_twiss = line.twiss(method='6d')\n",
    "twiss_init = _twiss.get_twiss_init(at_element=ee_at_dict[cycle_at])\n",
    "co_dict    = twiss_init.particle_on_co.copy(_context=xo.context_default).to_dict()\n",
    "WW      = twiss_init.W_matrix\n",
    "betzeta = WW[4, 4]**2 + WW[4, 5]**2\n",
    "nemitt_zeta = ((sigma_z**2/betzeta) * (co_dict['beta0'] * co_dict['gamma0']))[0]\n",
    "#==============================\n",
    "\n",
    "# Generating particles\n",
    "#==============================\n",
    "num_particles = config['particles']['num_particles']\n",
    "mtd_config = config[config['particles']['type']]\n",
    "\n",
    "# HYPERSPHERE\n",
    "#==============================\n",
    "if config['particles']['type'] == 'hypersphere':\n",
    "    coordinates = phys.hypersphere( N       = num_particles, \n",
    "                                    D       = 6, \n",
    "                                    r       = [ mtd_config['rx_sig'],\n",
    "                                                mtd_config['rx_sig'],\n",
    "                                                mtd_config['ry_sig'],\n",
    "                                                mtd_config['ry_sig'],\n",
    "                                                1.5*mtd_config['rzeta_sig'],\n",
    "                                                mtd_config['rzeta_sig']], \n",
    "                                    seed    = mtd_config['seed'], \n",
    "                                    unpack  = True)\n",
    "\n",
    "# GRID\n",
    "#==============================\n",
    "elif config['particles']['type'] == 'grid':\n",
    "    grid_size = int(np.floor(np.sqrt(num_particles)))\n",
    "    x,y = np.meshgrid(  mtd_config['offset_x']+np.linspace(0,mtd_config['max_x'],grid_size),\n",
    "                        mtd_config['offset_y']+np.linspace(0,mtd_config['max_y'],grid_size))\n",
    "    \n",
    "    num_particles = len(x.flatten())\n",
    "    coordinates = np.array([x.flatten(),\n",
    "                            np.zeros(num_particles),\n",
    "                            y.flatten(),\n",
    "                            np.zeros(num_particles),\n",
    "                            mtd_config['zeta']*np.ones(num_particles),\n",
    "                            np.zeros(num_particles)])\n",
    "#==============================\n",
    "\n",
    "                \n",
    "    \n",
    "import scipy\n",
    "_, _ , matcher = xp.generate_longitudinal_coordinates(line=line, num_particles=100, sigma_z=0.09, engine='single-rf-harmonic', return_matcher=True)\n",
    "n_particles = int(num_particles)\n",
    "m = np.random.uniform(size=n_particles) * 0.95\n",
    "K = scipy.special.ellipk(m)\n",
    "G = 2.*K/np.pi\n",
    "\n",
    "theta = np.random.uniform(size=n_particles)*2.*np.pi\n",
    "\n",
    "sn, cn, dn, ph = scipy.special.ellipj(G*theta,m)\n",
    "\n",
    "tau = 2./matcher.B*np.arcsin(np.sqrt(m)*sn)\n",
    "ptau = np.sqrt(2*matcher.A*m/matcher.C)*cn\n",
    "\n",
    "\n",
    "# # Generating xsuite particles\n",
    "# particles = xp.build_particles( line        = line,\n",
    "#                                 x_norm      = coordinates[0,:],\n",
    "#                                 px_norm     = coordinates[1,:],\n",
    "#                                 y_norm      = coordinates[2,:],\n",
    "#                                 py_norm     = coordinates[3,:],\n",
    "#                                 zeta_norm   = coordinates[4,:],\n",
    "#                                 pzeta_norm  = coordinates[5,:],\n",
    "#                                 nemitt_x    = nemitt_x, \n",
    "#                                 nemitt_y    = nemitt_y,\n",
    "#                                 nemitt_zeta = nemitt_zeta,\n",
    "#                                 _context    = context)\n",
    "\n",
    "# Generating xsuite particles\n",
    "particles = xp.build_particles( line        = line,\n",
    "                                x_norm      = coordinates[0,:],\n",
    "                                px_norm     = coordinates[1,:],\n",
    "                                y_norm      = coordinates[2,:],\n",
    "                                py_norm     = coordinates[3,:],\n",
    "                                zeta        = tau*co_dict['beta0'],\n",
    "                                pzeta       = ptau/co_dict['beta0'],\n",
    "                                nemitt_x    = nemitt_x, \n",
    "                                nemitt_y    = nemitt_y,\n",
    "                                nemitt_zeta = nemitt_zeta,\n",
    "                                _context    = context)\n",
    "\n",
    "# Going back to normalized:\n",
    "XX_sig = xPlus._W_phys2norm(particles.x,particles.px,particles.y,particles.py,particles.zeta,particles.pzeta, \n",
    "                            W_matrix    = twiss_init.W_matrix,\n",
    "                            co_dict     = twiss_init.particle_on_co.copy(_context=xo.context_default).to_dict(), \n",
    "                            nemitt_x    = nemitt_x, \n",
    "                            nemitt_y    = nemitt_y, \n",
    "                            nemitt_zeta = nemitt_zeta)\n",
    "\n",
    "# Checking:\n",
    "assert np.allclose(XX_sig[0,:],coordinates[0,:],atol=1e-13, rtol=0), 'Error in x'\n",
    "assert np.allclose(XX_sig[1,:],coordinates[1,:],atol=1e-13, rtol=0), 'Error in px'\n",
    "assert np.allclose(XX_sig[2,:],coordinates[2,:],atol=1e-13, rtol=0), 'Error in y'\n",
    "assert np.allclose(XX_sig[3,:],coordinates[3,:],atol=1e-13, rtol=0), 'Error in py'\n",
    "# assert np.allclose(XX_sig[4,:],coordinates[4,:],atol=1e-13, rtol=0), 'Error in zeta'\n",
    "# assert np.allclose(XX_sig[5,:],coordinates[5,:],atol=1e-13, rtol=0), 'Error in pzeta'\n",
    "\n",
    "\n",
    "# Exporting\n",
    "export_path = config['particles']['path'] + f'/{config[\"particles\"][\"name\"]}.parquet'\n",
    "data = pd.DataFrame({'particle':particles.particle_id,  'x'     : particles.x,\n",
    "                                                        'px'    : particles.px,\n",
    "                                                        'y'     : particles.y,\n",
    "                                                        'py'    : particles.py,\n",
    "                                                        'zeta'  : particles.zeta,\n",
    "                                                        'pzeta' : particles.pzeta,\n",
    "                                                        'x_norm'    : coordinates[0,:],\n",
    "                                                        'px_norm'   : coordinates[1,:],\n",
    "                                                        'y_norm'    : coordinates[2,:],\n",
    "                                                        'py_norm'   : coordinates[3,:],\n",
    "                                                        'zeta_norm' : coordinates[4,:],\n",
    "                                                        'pzeta_norm': coordinates[5,:],\n",
    "                                                        })\n",
    "data.to_parquet(export_path)\n",
    "\n",
    "\n",
    "# Plotting:\n",
    "export_path = config['particles']['path'] + f'/VIEWER_{config[\"particles\"][\"name\"]}.html'\n",
    "particles_to_HTML(particles,coordinates,collider,config,[nemitt_x,nemitt_y,nemitt_zeta],rfbucket,export_path)\n",
    "#==============================\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinkedArrayCpu([-1.58006643e-04,  1.39476934e-04, -3.76641732e-05, ...,\n",
       "                -3.90591208e-05,  1.60466806e-05,  1.34103735e-05])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particles.ptau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18556062,  0.12483156,  0.05979008, ...,  0.13045053,\n",
       "        0.04262857, -0.23441785])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.58006643e-04,  1.39476934e-04, -3.76641732e-05, ...,\n",
       "       -3.90591208e-05,  1.60466806e-05,  1.34103735e-05])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptau"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-BB",
   "language": "python",
   "name": "py-bb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
