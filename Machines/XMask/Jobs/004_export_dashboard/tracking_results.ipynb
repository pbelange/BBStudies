{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import itertools\n",
    "import importlib\n",
    "\n",
    "# BOKEH\n",
    "import bokeh.plotting as bk\n",
    "import bokeh.models as bkmod\n",
    "import bokeh.layouts as bklay\n",
    "import bokeh.palettes as bkpalettes\n",
    "import bokeh.util.hex as bkhex\n",
    "import bokeh.transform as bktrfm\n",
    "import bokeh.colors as bkcolors\n",
    "\n",
    "bk.output_notebook()\n",
    "\n",
    "# xsuite\n",
    "import xtrack as xt\n",
    "import xmask as xm\n",
    "import xfields as xf\n",
    "import xpart as xp\n",
    "\n",
    "# Custom imports\n",
    "import bokeh_tools as bktools\n",
    "import Presets as bkpresets\n",
    "\n",
    "# BBStudies\n",
    "import sys\n",
    "sys.path.append('/Users/pbelanger/ABPLocal/BBStudies')\n",
    "import BBStudies.Tracking.XsuitePlus as xPlus\n",
    "import BBStudies.Tracking.InteractionPoint as inp\n",
    "import BBStudies.Physics.Detuning as tune\n",
    "import BBStudies.Plotting.BBPlots as bbplt\n",
    "import BBStudies.Physics.Base as phys\n",
    "import BBStudies.Physics.Constants as cst\n",
    "\n",
    "\n",
    "\n",
    "# Setting default values\n",
    "#------------------------------------------------\n",
    "BOKEH_FIGS = {}\n",
    "# _default_fig_width  = 2000\n",
    "_default_fig_width  = 1500\n",
    "_default_fig_height = 400\n",
    "_default_fig_pad    = 100\n",
    "\n",
    "\n",
    "# tracking_path = 'zfruits/BBB_Signature/FULL/'\n",
    "# tracked   = xPlus.Tracking_Interface.from_parquet(tracking_path ,partition_name='CHUNK')\n",
    "\n",
    "data_path = '../003_particle_dist_and_track/zfruits/BBB_Signature_V2/DATA/'\n",
    "data      = xPlus.Tracking_Interface.from_parquet(data_path,partition_name='BUNCH',partition_ID='0220')\n",
    "\n",
    "_cpt      = xPlus.Tracking_Interface.from_parquet(data_path.replace('DATA','CHECKPOINTS'),partition_name='BUNCH',partition_ID='0220')\n",
    "data._checkpoint = _cpt._checkpoint\n",
    "\n",
    "# _trk      = xPlus.Tracking_Interface.from_parquet(data_path.replace('DATA','FULL/BUNCH_0220'),partition_name='CHUNK',handpick_particles = [1, 9, 536, 4883])\n",
    "# data._df          = _trk.df\n",
    "\n",
    "\n",
    "\n",
    "#bk.show(bklay.column(BOKEH_FIGS['lattice'],BOKEH_FIGS['twiss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_html(dictionaries, headers, margin=10, width=int(_default_fig_width)-10,force_width=120):\n",
    "    def format_value(key,value):\n",
    "        if isinstance(value, dict):\n",
    "            return dict_to_html([value], headers=[''], margin=0, width=width,force_width=force_width)\n",
    "        return str(value)\n",
    "\n",
    "    html_content = \"\"\n",
    "    for i, d in enumerate(dictionaries):\n",
    "        # Add a tab character before the div content\n",
    "        html_content += f\"\\t<div style='background-color: black; color: white; padding: 10px; border-radius: 5px; margin: 0 0 0 {margin}px; width: {width}px;'><h2>{headers[i]}</h2><ul style='list-style-type: none; padding: 0; margin: 0;'>\"\n",
    "        for key, value in d.items():\n",
    "            # Use flexbox for better alignment\n",
    "            if force_width:\n",
    "                html_content += f\"\\t\\t<li style='line-height: 1; display: flex;'><div style='width: {force_width}px;'><strong>{key}:</strong></div><div style='padding-left: 10px;'>{format_value(key,value)}</div></li>\"\n",
    "            else:\n",
    "                html_content += f\"\\t\\t<li style='line-height: 1; display: flex;'><div><strong>{key}:</strong></div><div style='padding-left: 10px;'>{format_value(key,value)}</div></li>\"\n",
    "        html_content += \"</ul></div>\"\n",
    "        if i < len(dictionaries) - 1:\n",
    "            # Add a tab character before the horizontal line\n",
    "            html_content += \"\\t<hr style='margin: 5px;'>\"\n",
    "    return html_content\n",
    "\n",
    "\n",
    "import ruamel.yaml\n",
    "ryaml = ruamel.yaml.YAML()\n",
    "def read_configuration(config_path=\"config.yaml\"):\n",
    "    # Read configuration for simulations\n",
    "    with open(config_path, \"r\") as fid:\n",
    "        config = ryaml.load(fid)\n",
    "\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "config = read_configuration('../003_particle_dist_and_track/config.yaml')\n",
    "config_collider = read_configuration('../001_configure_collider/config.yaml')['config_collider']\n",
    "\n",
    "config_info = bkmod.Div(text=dict_to_html([config],['Collider config.yaml']),width=_default_fig_width, height=1000)\n",
    "config_collider_info = bkmod.Div(text=dict_to_html([config_collider],['Collider config.yaml'],force_width=0),width=_default_fig_width, height=1000)\n",
    "\n",
    "\n",
    "metadata = data.to_dict()\n",
    "metadata.pop('parquet_data');\n",
    "metadata.pop('W_matrix');\n",
    "metadata.pop('particle_on_co');\n",
    "tracking_info = bkmod.Div(text=dict_to_html([metadata],['Tracking Info']),width=_default_fig_width, height=300)\n",
    "\n",
    "\n",
    "\n",
    "bk.show(bklay.column(config_info))\n",
    "# bk.show(bklay.column(config_collider_info))\n",
    "# bk.show(bklay.column(tracking_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data.data.stop_at_turn - data.data.start_at_turn).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['tracking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_dict().pop('W_matrix')\n",
    "\n",
    "metadata = data.to_dict()\n",
    "metadata.pop('parquet_data');\n",
    "metadata.pop('W_matrix');\n",
    "metadata.pop('particle_on_co');\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_name(group):\n",
    "    return group.name\n",
    "\n",
    "data.data.groupby('Chunk ID').apply(return_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction action\n",
    "J_df = data.checkpoint[['BUNCH','Chunk ID','turn','particle']]\n",
    "J_df.insert(4,'Jx/emitt',1/2 * (data.checkpoint_sig.x_sig**2 + data.checkpoint_sig.px_sig**2))\n",
    "J_df.insert(5,'Jy/emitt',1/2 * (data.checkpoint_sig.y_sig**2 + data.checkpoint_sig.py_sig**2))\n",
    "J_df.dropna(inplace=True)\n",
    "\n",
    "# Making Hextile grid\n",
    "J_min  = 0\n",
    "J_max  = 50\n",
    "n_bins = 300\n",
    "\n",
    "_size        = (J_max-J_min)/n_bins\n",
    "_orientation = 'pointytop'\n",
    "\n",
    "\n",
    "# Creating hextile template\n",
    "x_corners = [J_df['Jx/emitt'].min(),J_df['Jx/emitt'].max()]\n",
    "y_corners = [J_df['Jy/emitt'].min(),J_df['Jy/emitt'].max()]\n",
    "XX,YY    = np.meshgrid(np.arange(J_df['Jx/emitt'].min(),J_df['Jx/emitt'].max(),_size),\n",
    "                    np.arange(J_df['Jy/emitt'].min(),J_df['Jy/emitt'].max(),_size))\n",
    "hextiles_template = bkhex.hexbin(np.array(list(XX.flatten())+x_corners), np.array(list(YY.flatten())+y_corners), size=_size,orientation=_orientation)\n",
    "hextiles_template['counts']  = 0\n",
    "hextiles_template = hextiles_template.rename(columns={'counts':'counts:active'}).set_index(['q','r'])\n",
    "\n",
    "# Looping over chunks\n",
    "for name,group in J_df.groupby('Chunk ID'):\n",
    "    # Forcing corner values to have same grid.\n",
    "    within_limits = (group['Jx/emitt'] < J_max)&(group['Jy/emitt'] < J_max)\n",
    "    data_x = np.array(list(group['Jx/emitt'][within_limits]) + [J_min,J_max])\n",
    "    data_y = np.array(list(group['Jy/emitt'][within_limits]) + [J_min,J_max])\n",
    "    _hex = bkhex.hexbin(data_x,data_y, size=_size,orientation=_orientation)\n",
    "\n",
    "    # Removing corner values\n",
    "    _hex = _hex[1:-1]\n",
    "\n",
    "    # Adding chunk ID\n",
    "    hextiles_template.insert(name+1,f'counts:{name}',_hex.set_index(['q','r'])['counts'])\n",
    "\n",
    "\n",
    "# setting empty bins to 0\n",
    "# hextiles_template = hextiles_template.fillna(0).reset_index()\n",
    "# hextiles_template = hextiles_template.reset_index()\n",
    "hextiles_template.reset_index(inplace=True)\n",
    "hextiles_template['counts:active'] = hextiles_template['counts:0']\n",
    "hextiles_template\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.compute_intensity(coll_opening=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.coord_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload bkpresets\n",
    "\n",
    "importlib.reload(bkpresets)\n",
    "BOKEH_FIGS['x-px'] = bkpresets.make_scatter_fig(data.coord_sig,xy=('x_sig','px_sig'),title='x norm. phase space',width=_default_fig_width//4,height=_default_fig_height)\n",
    "BOKEH_FIGS['y-py'] = bkpresets.make_scatter_fig(data.coord_sig,xy=('y_sig','py_sig'),title='y norm. phase space',width=_default_fig_width//4,height=_default_fig_height)\n",
    "BOKEH_FIGS['zeta-pzeta'] = bkpresets.make_scatter_fig(data.coord_sig,xy=('zeta_sig','pzeta_sig'),title='zeta norm. phase space',width=_default_fig_width//4,height=_default_fig_height)\n",
    "\n",
    "BOKEH_FIGS['x-y'] = bkpresets.make_scatter_fig(data.data,xy=('x_min','y_min'),title='Transverse norm space',width=3*_default_fig_width//4,height=2*_default_fig_height)\n",
    "\n",
    "\n",
    "bktools.set_aspect(BOKEH_FIGS['x-px']       , x_lim=(-6,6),y_lim=(-6,6), aspect=1, margin=0)\n",
    "bktools.set_aspect(BOKEH_FIGS['y-py']       , x_lim=(-6,6),y_lim=(-6,6), aspect=1, margin=0)\n",
    "bktools.set_aspect(BOKEH_FIGS['zeta-pzeta'] , x_lim=(-1,1),y_lim=(-1,1), aspect=1, margin=0)\n",
    "bktools.set_aspect(BOKEH_FIGS['x-y']        , x_lim=(-6,6),y_lim=(-6,6), aspect=1, margin=0)\n",
    "\n",
    "\n",
    "\n",
    "grid = bk.column([bklay.gridplot([[BOKEH_FIGS['x-px'] ,BOKEH_FIGS['y-py'] ,BOKEH_FIGS['zeta-pzeta']]],toolbar_location='right'),\n",
    "                  bklay.gridplot([[BOKEH_FIGS['x-y'] ]],toolbar_location='right')])\n",
    "\n",
    "# grid = bklay.layout([ [BOKEH_FIGS['x-px'] ,BOKEH_FIGS['y-py'] ,BOKEH_FIGS['zeta-pzeta']], \n",
    "#                         [BOKEH_FIGS['x-y'] ]],)\n",
    "bk.show(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(bkpresets)\n",
    "BOKEH_FIGS['Intensity'] = bkpresets.make_intensity_fig(data,title='Intensity',width=3*_default_fig_width//4,height=_default_fig_height)\n",
    "\n",
    "\n",
    "grid = bklay.gridplot([[BOKEH_FIGS['Intensity']]],toolbar_location='right')\n",
    "bk.show(grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_coll(_df,coll_opening = 5):\n",
    "    \n",
    "    # Resetting values\n",
    "    #-----------------------------\n",
    "    _width  = _df['width'].unique()[0]\n",
    "    _height = _df['height'].unique()[0]\n",
    "    _df['xs']   = 6*[np.array([0,0,_width,_width])]\n",
    "    _df['ys']   = 6*[np.array([-_height/2,_height/2,_height/2,-_height/2])]\n",
    "\n",
    "    # Distributing colls on x-axis\n",
    "    #-----------------------------\n",
    "    _df['xs'] += coll_opening*_df['sigma']\n",
    "    _df.loc[_df.name.str.contains('left|bottom'),'xs']   *= -1\n",
    "\n",
    "    # Rotating according to angle\n",
    "    _x,_y  = np.stack(_df['xs']),np.stack(_df['ys'])\n",
    "    _angle = np.stack(_df['angle'].apply(lambda angle: list(np.repeat(angle,4))))\n",
    "    _x_rot = _x*np.cos(_angle) - _y*np.sin(_angle)\n",
    "    _y_rot = _x*np.sin(_angle) + _y*np.cos(_angle)\n",
    "\n",
    "\n",
    "    _df['xs'] = list(_x_rot)\n",
    "    _df['ys'] = list(_y_rot)\n",
    "\n",
    "    # Returning in mm\n",
    "    # _df['xs'] *= \n",
    "    # _df['ys'] *= \n",
    "\n",
    "    return _df\n",
    "\n",
    "\n",
    "def excursion_polygon(row):\n",
    "    # skew col : y = ax + b\n",
    "    skew_angle = 127.5\n",
    "    a = np.tan(np.deg2rad(skew_angle-90))\n",
    "    b = np.max([np.abs(row['skew_max']),np.abs(row['skew_min'])])/np.cos(np.deg2rad(skew_angle-90))\n",
    "\n",
    "    # skew col : y = ax - b, x = (y+b)/a\n",
    "    x1 = [row['x_max'],a*row['x_max'] - b]\n",
    "    x2 = [(row['y_min']+b)/a,row['y_min']]\n",
    "\n",
    "    # skew col : y = -ax - b, x = -(y+b)/a\n",
    "    x3 = [-(row['y_min']+b)/a,row['y_min']]\n",
    "    x4 = [row['x_min'],-a*row['x_min'] - b]\n",
    "\n",
    "    # skew col : y = ax + b, x = (y-b)/a\n",
    "    x5 = [row['x_min'],a*row['x_min'] + b]\n",
    "    x6 = [(row['y_max']-b)/a,row['y_max']]\n",
    "\n",
    "    # skew col : y = -ax + b, x = -(y-b)/a\n",
    "    x7 = [-(row['y_max']-b)/a,row['y_max']]\n",
    "    x8 = [row['x_max'],-a*row['x_max'] + b]\n",
    "\n",
    "    if x5[1]<x4[1]:\n",
    "        x4[1],x5[1] = x5[1],x4[1]\n",
    "    \n",
    "    if x8[1]<x1[1]:\n",
    "        x1[1],x8[1] = x8[1],x1[1]\n",
    "\n",
    "    return [x1[0],x2[0],x3[0],x4[0],x5[0],x6[0],x7[0],x8[0]], [x1[1],x2[1],x3[1],x4[1],x5[1],x6[1],x7[1],x8[1]]\n",
    "\n",
    "#=========================================================================================================================\n",
    "def make_collimation_fig(data,title=None,width=2000,height=400):\n",
    "\n",
    "    # Creating Figure\n",
    "    #=====================================\n",
    "    fig = bk.figure(output_backend  = \"webgl\",\n",
    "                    height          = height, \n",
    "                    width           = width,\n",
    "                    title           = title, \n",
    "                    tools           = \"box_zoom,pan,reset,save,wheel_zoom\",\n",
    "                    active_drag     = \"box_zoom\",\n",
    "                    active_scroll   = \"wheel_zoom\",\n",
    "                    toolbar_location= \"right\")\n",
    "\n",
    "\n",
    "    # Saving tools to tags\n",
    "    # _palette = bkpalettes.Viridis8\n",
    "    _palette = bkpalettes.Spectral10\n",
    "    fig.tags = [{str(type(t)).split('.')[-1].split('\\'')[0]:t for t in fig.tools},\n",
    "                {'palette':_palette}]\n",
    "    # fig.tags[0]['WheelZoomTool'].update(dimensions = 'height')\n",
    "    # fig.tags[0]['HoverTool'].update(tooltips = [('Variable', '$name'),('s [m]','$x{0}'),(f'Value', '$y'),('Element','@name')])\n",
    "    # fig.tags[0]['HoverTool'].update(tooltips = [('Variable', '$name'),('s [m]','@s'),(f'Value', '$y'),('Element','@name')])\n",
    "\n",
    "    # Putting legend outside\n",
    "    # fig.add_layout(bkmod.Legend(), 'right')\n",
    "    #=====================================\n",
    "\n",
    "    coll_opening = 5\n",
    "    coll_alpha = np.deg2rad(127.5)\n",
    "    pipe_r     = cst.LHC_W_BEAM_SCREEN/2\n",
    "    coll_df    = pd.DataFrame({'name'   :  ['H_left','H_right','V_top','V_bottom','S_top','S_bottom'],\n",
    "                               'width'  :  pipe_r*np.ones(6),\n",
    "                               'height' :2*pipe_r*np.ones(6),\n",
    "                               'xs'     :6*[np.zeros(4)],\n",
    "                               'ys'     :6*[np.zeros(4)],\n",
    "                                'angle' :[0,0,np.pi/2,np.pi/2,coll_alpha,coll_alpha],\n",
    "                                'sigma' :[data.sig_x_coll,data.sig_x_coll,data.sig_y_coll,data.sig_y_coll,data.sig_skew_coll,data.sig_skew_coll]})\n",
    "\n",
    "        \n",
    "    coll_df = update_coll(coll_df,coll_opening=coll_opening)\n",
    "    source  = bkmod.ColumnDataSource(coll_df)\n",
    "    \n",
    "    fig.patches(xs='xs', ys='ys',alpha=1,color='gray',source=source)\n",
    "\n",
    "\n",
    "    # Crop at beam pipe\n",
    "    _x_pipe = np.array([-2*pipe_r] + list(np.linspace(-pipe_r,pipe_r,200)) + [2*pipe_r])\n",
    "    _y_pipe = np.sqrt(pipe_r**2 - _x_pipe**2)\n",
    "    _y_pipe[np.abs(_x_pipe)>pipe_r] = 0\n",
    "    fig.varea(x=_x_pipe,y1=2*pipe_r*np.ones(len(_x_pipe)),y2=_y_pipe  ,color='white',alpha=1)\n",
    "    fig.varea(x=_x_pipe,y2=-2*pipe_r*np.ones(len(_x_pipe)),y1=-_y_pipe,color='white',alpha=1)\n",
    "\n",
    "\n",
    "    # Adding particle trajectory:\n",
    "    last_turn    = data.data.start_at_turn.max()\n",
    "    last_turn_df = data.data.groupby('start_at_turn').get_group(last_turn).set_index('particle')\n",
    "\n",
    "    sigma_bins     = [1,3,5,7,9,12]\n",
    "    bin_values     = [np.sqrt(2*(i*data.sig_x)**2 + 2*(i*data.sig_y**2)) for i in sigma_bins]\n",
    "    part_selection = pd.cut(np.sqrt(last_turn_df.x_max**2 +last_turn_df.px_max**2 + last_turn_df.y_max**2 +last_turn_df.py_max**2),bins=bin_values)\n",
    "    part_chosen = []\n",
    "    for name, group in part_selection.groupby(part_selection,observed=True):\n",
    "        part_chosen.append(group.index.values[1])\n",
    "\n",
    "    # part_chosen = part_chosen[::2]\n",
    "    print(part_chosen)\n",
    "    # part_chosen =[part_chosen[2]]\n",
    "    for part_idx,color in zip(part_chosen,fig.tags[1]['palette']):\n",
    "        _part = data.data.groupby('particle').get_group(part_idx)\n",
    "        polygon = pd.DataFrame(_part.apply(lambda row:excursion_polygon(row),axis=1).to_list(),columns=['x','y'])\n",
    "\n",
    "\n",
    "        source = bkmod.ColumnDataSource(pd.DataFrame({'x':polygon.x[-1:].sum(),'y':polygon.y[-1:].sum()}))\n",
    "        fig.line('x','y', alpha=0.8,color=color,legend_label= f'Particle {part_idx}',source=source)\n",
    "        # fig.scatter('x','y', alpha=0.8,color=color, source=source)\n",
    "\n",
    "    # for part_idx,color in zip(part_chosen,fig.tags[1]['palette']):\n",
    "    #     _part = data.checkpoint.groupby('particle').get_group(part_idx)\n",
    "\n",
    "    #     source = bkmod.ColumnDataSource(_part[['x','y']])\n",
    "    #     fig.line('x','y', alpha=0.6,color=color, source=source)\n",
    "    #     fig.scatter('x','y', alpha=0.6,color=color, source=source)\n",
    "\n",
    "\n",
    "    # for part_idx,color in zip(part_chosen,fig.tags[1]['palette']):\n",
    "    #     _part = data.checkpoint.groupby('particle').get_group(part_idx)\n",
    "\n",
    "    #     source = bkmod.ColumnDataSource(_part[['x','y']])\n",
    "    #     fig.scatter('x','y', alpha=0.6,color=color, source=source)\n",
    "\n",
    "    # fig.rect(x=[0], y=[0], width=0.00005, height=40, color=\"black\",angle=np.deg2rad(127.5-90))\n",
    "    # fig.rect(x=[0], y=[0], width=0.00005, height=40, color=\"black\",angle=np.deg2rad(180-127.5-90))\n",
    "    # fig.scatter('0','y_max', alpha=0.3,color='blue', source=source)\n",
    "    # fig.scatter('x_max','0', alpha=0.3,color='blue', source=source)\n",
    "    # fig.scatter('x_min','0', alpha=0.3,color='blue', source=source)\n",
    "    # Axis and Legend\n",
    "    #=====================================\n",
    "\n",
    "    fig.xaxis.axis_label = 'x [m]'\n",
    "    fig.yaxis.axis_label = 'y [m]'\n",
    "    fig.legend.title     = r'Particles ID'\n",
    "    fig.legend.click_policy=\"hide\"\n",
    "    # fig.x_range=bkmod.Range1d(-6, 6)\n",
    "    # fig.y_range=bkmod.Range1d(-6, 6)\n",
    "    # fig.match_aspect=True\n",
    "\n",
    "    #=====================================\n",
    "\n",
    "    return fig\n",
    "\n",
    "fig = make_collimation_fig(data,title='Collimation',width=1000,height=700)\n",
    "bktools.set_aspect(fig , x_lim=(-3e-3,3e-3),y_lim=(-3e-3,3e-3), aspect=1, margin=0)\n",
    "bk.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_coll(_df,coll_opening = 5):\n",
    "    \n",
    "    # Resetting values\n",
    "    #-----------------------------\n",
    "    _width  = _df['width'].unique()[0]\n",
    "    _height = _df['height'].unique()[0]\n",
    "    _df['xs']   = 6*[np.array([0,0,_width,_width])]\n",
    "    _df['ys']   = 6*[np.array([-_height/2,_height/2,_height/2,-_height/2])]\n",
    "\n",
    "    # Distributing colls on x-axis\n",
    "    #-----------------------------\n",
    "    _df['xs'] += coll_opening*_df['sigma']\n",
    "    _df.loc[_df.name.str.contains('left|bottom'),'xs']   *= -1\n",
    "\n",
    "    # Rotating according to angle\n",
    "    _x,_y  = np.stack(_df['xs']),np.stack(_df['ys'])\n",
    "    _angle = np.stack(_df['angle'].apply(lambda angle: list(np.repeat(angle,4))))\n",
    "    _x_rot = _x*np.cos(_angle) - _y*np.sin(_angle)\n",
    "    _y_rot = _x*np.sin(_angle) + _y*np.cos(_angle)\n",
    "\n",
    "\n",
    "    _df['xs'] = list(_x_rot)\n",
    "    _df['ys'] = list(_y_rot)\n",
    "\n",
    "    # Returning in mm\n",
    "    # _df['xs'] *= \n",
    "    # _df['ys'] *= \n",
    "\n",
    "    return _df\n",
    "\n",
    "\n",
    "def excursion_polygon(row):\n",
    "    # skew col : y = ax + b\n",
    "    skew_angle = 127.5\n",
    "    a = np.tan(np.deg2rad(skew_angle-90))\n",
    "    b = np.max([np.abs(row['skew_max']),np.abs(row['skew_min'])])/np.cos(np.deg2rad(skew_angle-90))\n",
    "\n",
    "    # skew col : y = ax - b, x = (y+b)/a\n",
    "    x1 = [row['x_max'],a*row['x_max'] - b]\n",
    "    x2 = [(row['y_min']+b)/a,row['y_min']]\n",
    "\n",
    "    # skew col : y = -ax - b, x = -(y+b)/a\n",
    "    x3 = [-(row['y_min']+b)/a,row['y_min']]\n",
    "    x4 = [row['x_min'],-a*row['x_min'] - b]\n",
    "\n",
    "    # skew col : y = ax + b, x = (y-b)/a\n",
    "    x5 = [row['x_min'],a*row['x_min'] + b]\n",
    "    x6 = [(row['y_max']-b)/a,row['y_max']]\n",
    "\n",
    "    # skew col : y = -ax + b, x = -(y-b)/a\n",
    "    x7 = [-(row['y_max']-b)/a,row['y_max']]\n",
    "    x8 = [row['x_max'],-a*row['x_max'] + b]\n",
    "\n",
    "    if x5[1]<x4[1]:\n",
    "        x4[1],x5[1] = x5[1],x4[1]\n",
    "    \n",
    "    if x8[1]<x1[1]:\n",
    "        x1[1],x8[1] = x8[1],x1[1]\n",
    "\n",
    "    return [x1[0],x2[0],x3[0],x4[0],x5[0],x6[0],x7[0],x8[0]], [x1[1],x2[1],x3[1],x4[1],x5[1],x6[1],x7[1],x8[1]]\n",
    "\n",
    "#=========================================================================================================================\n",
    "\n",
    "\n",
    "def lost_condition(x,y,x_skew,y_skew,coll_x,coll_y,coll_s):\n",
    "            return ((np.abs(x)>coll_x)|(np.abs(y)>coll_y)|(np.abs(x_skew)>coll_s)|(np.abs(y_skew)>coll_s))\n",
    "\n",
    "\n",
    "\n",
    "def condition_in_ring(x1,x2,y1,y2,s1,s2,collx1,collx2,colly1,colly2,colls1,colls2):\n",
    "    _out_ROI_min  =((np.abs(x1)>collx1)|(np.abs(x2)>collx1) | \n",
    "                    (np.abs(y1)>colly1)|(np.abs(y2)>colly1) | \n",
    "                    (np.abs(s1)>colls1)|(np.abs(s2)>colls1))\n",
    "    _out_ROI_max  =((np.abs(x1)>collx2)|(np.abs(x2)>collx2) | \n",
    "                    (np.abs(y1)>colly2)|(np.abs(y2)>colly2) | \n",
    "                    (np.abs(s1)>colls2)|(np.abs(s2)>colls2))\n",
    "    return ((_out_ROI_min) & (~_out_ROI_max))\n",
    "\n",
    "\n",
    "\n",
    "def make_ROI(x1,x2,y1,y2,s1,s2,collx1,collx2,colly1,colly2,colls1,colls2,force_normalisation = False):\n",
    "    _out_ROI_min  =((np.abs(x1)>collx1)|(np.abs(x2)>collx1) | \n",
    "                    (np.abs(y1)>colly1)|(np.abs(y2)>colly1) | \n",
    "                    (np.abs(s1)>colls1)|(np.abs(s2)>colls1))\n",
    "    _out_ROI_max  =((np.abs(x1)>collx2)|(np.abs(x2)>collx2) | \n",
    "                    (np.abs(y1)>colly2)|(np.abs(y2)>colly2) | \n",
    "                    (np.abs(s1)>colls2)|(np.abs(s2)>colls2))\n",
    "    \n",
    "    ROI = ((_out_ROI_min) & (~_out_ROI_max))\n",
    "    # Splitting in 3 planes\n",
    "    ROI_x = ROI&((np.abs(x1)>collx1)|(np.abs(x2)>collx1))\n",
    "    ROI_y = ROI&((np.abs(y1)>colly1)|(np.abs(y2)>colly1))\n",
    "    ROI_s = ROI&((np.abs(s1)>colls1)|(np.abs(s2)>colls1))\n",
    "    if force_normalisation:\n",
    "        ROI_s = ROI&(~ROI_x)&(~ROI_y)\n",
    "    # print('lol')\n",
    "    return ROI,ROI_x,ROI_y,ROI_s\n",
    "\n",
    "def make_collimation_fig(data,title=None,width=2000,height=400):\n",
    "\n",
    "    # Creating Figure\n",
    "    #=====================================\n",
    "    fig = bk.figure(output_backend  = \"webgl\",\n",
    "                    height          = height, \n",
    "                    width           = width,\n",
    "                    title           = title, \n",
    "                    tools           = \"box_zoom,pan,reset,save,hover,wheel_zoom\",\n",
    "                    active_drag     = \"box_zoom\",\n",
    "                    active_scroll   = \"wheel_zoom\",\n",
    "                    toolbar_location= \"right\")\n",
    "\n",
    "\n",
    "    # Saving tools to tags\n",
    "    # _palette = bkpalettes.Viridis8\n",
    "    _palette = bkpalettes.Spectral10\n",
    "    fig.tags = [{str(type(t)).split('.')[-1].split('\\'')[0]:t for t in fig.tools},\n",
    "                {'palette':_palette}]\n",
    "    # fig.tags[0]['WheelZoomTool'].update(dimensions = 'height')\n",
    "    # fig.tags[0]['HoverTool'].update(tooltips = [('Variable', '$name'),('s [m]','$x{0}'),(f'Value', '$y'),('Element','@name')])\n",
    "    fig.tags[0]['HoverTool'].update(tooltips = [('Collimator [sigma_coll]','@opening'),('Count', '@{counts:active}')])\n",
    "\n",
    "    # Putting legend outside\n",
    "    # fig.add_layout(bkmod.Legend(), 'right')\n",
    "    #=====================================\n",
    "\n",
    "    coll_opening = 10\n",
    "    coll_alpha = np.deg2rad(127.5)\n",
    "    pipe_r     = cst.LHC_W_BEAM_SCREEN/2\n",
    "    coll_df    = pd.DataFrame({'name'   :  ['H_left','H_right','V_top','V_bottom','S_top','S_bottom'],\n",
    "                               'width'  :  pipe_r*np.ones(6),\n",
    "                               'height' :2*pipe_r*np.ones(6),\n",
    "                               'xs'     :6*[np.zeros(4)],\n",
    "                               'ys'     :6*[np.zeros(4)],\n",
    "                                'angle' :[0,0,np.pi/2,np.pi/2,coll_alpha,coll_alpha],\n",
    "                                'sigma' :[data.sig_x_coll,data.sig_x_coll,data.sig_y_coll,data.sig_y_coll,data.sig_skew_coll,data.sig_skew_coll]})\n",
    "\n",
    "        \n",
    "    coll_df = update_coll(coll_df,coll_opening=coll_opening)\n",
    "    source  = bkmod.ColumnDataSource(coll_df)\n",
    "    \n",
    "    fig.patches(xs='xs', ys='ys',alpha=1,color='gray',source=source)\n",
    "\n",
    "\n",
    "    # Crop at beam pipe\n",
    "    _x_pipe = np.array([-2*pipe_r] + list(np.linspace(-pipe_r,pipe_r,200)) + [2*pipe_r])\n",
    "    _y_pipe = np.sqrt(pipe_r**2 - _x_pipe**2)\n",
    "    _y_pipe[np.abs(_x_pipe)>pipe_r] = 0\n",
    "    fig.varea(x=_x_pipe,y1=2*pipe_r*np.ones(len(_x_pipe)),y2=_y_pipe  ,color='white',alpha=1)\n",
    "    fig.varea(x=_x_pipe,y2=-2*pipe_r*np.ones(len(_x_pipe)),y1=-_y_pipe,color='white',alpha=1)\n",
    "\n",
    "\n",
    "        # Creating Hextiles\n",
    "    #=====================================\n",
    "    coll_values = np.linspace(0,10,50)\n",
    "    n_bins      = 300\n",
    "    coll_sig = np.max([data.sig_x_coll,data.sig_y_coll])\n",
    "    XX,YY    = np.meshgrid(np.linspace(-coll_values[-1]*coll_sig,coll_values[-1]*coll_sig,n_bins),\n",
    "                            np.linspace(-coll_values[-1]*coll_sig,coll_values[-1]*coll_sig,n_bins))\n",
    "\n",
    "    _size        = np.min(np.abs(np.diff(XX.flatten())))\n",
    "    _orientation = 'pointytop'\n",
    "\n",
    "    hextiles = bkhex.hexbin(XX.flatten(), YY.flatten(), _size)\n",
    "    _x,_y    = bkhex.axial_to_cartesian(hextiles.q,hextiles.r,size=_size,orientation=_orientation)\n",
    "    theta_unskew= -np.deg2rad(127.5)\n",
    "    _x_skew       = _x*np.cos(theta_unskew) - _y*np.sin(theta_unskew)\n",
    "    _y_skew       = _x*np.cos(-theta_unskew) - _y*np.sin(-theta_unskew)\n",
    "    hextiles.insert(0,'x',_x)\n",
    "    hextiles.insert(1,'y',_y)\n",
    "    hextiles.insert(2,'x_skew',_x_skew)\n",
    "    hextiles.insert(3,'y_skew',_y_skew)\n",
    "    hextiles.insert(4,'opening',np.nan)\n",
    "    hextiles.counts = np.nan\n",
    "    hextiles.rename(columns={'counts':'counts:active'},inplace=True)\n",
    "    #=====================================\n",
    "\n",
    "\n",
    "\n",
    "    _sig_x    = data.sig_x_coll\n",
    "    _sig_y    = data.sig_y_coll\n",
    "    _sig_skew = data.sig_skew_coll\n",
    "    # Looping over chunks\n",
    "\n",
    "    name  = 0\n",
    "    group = data.data.groupby('Chunk ID').get_group(name)\n",
    "    hextiles.insert(len(hextiles.columns),f'counts:{name}',np.nan)\n",
    "\n",
    "    total = 0\n",
    "    for coll_min,coll_max in zip(coll_values[:-1],coll_values[1:]):\n",
    "        \n",
    "        # Identifying Hex in ROI\n",
    "        \n",
    "        hex_,hex_x,hex_y,hex_s  = make_ROI( hextiles['x'],hextiles['x'],\n",
    "                                        hextiles['y'],hextiles['y'],\n",
    "                                        hextiles['x_skew'],hextiles['y_skew'],\n",
    "                                        coll_min*_sig_x,coll_max*_sig_x,\n",
    "                                        coll_min*_sig_y,coll_max*_sig_y,\n",
    "                                        coll_min*_sig_skew,coll_max*_sig_skew,force_normalisation=True)\n",
    "        hextiles.loc[(hex_x|hex_y|hex_s),f'opening'] = np.mean([coll_min,coll_max])\n",
    "\n",
    "\n",
    "        # Counts per collimators\n",
    "        #------------------------------------\n",
    "        count_,count_x,count_y,count_s = make_ROI( group['x_max'],group['x_min'],\n",
    "                                            group['y_max'],group['y_min'],\n",
    "                                            group['skew_max'],group['skew_min'],\n",
    "                                            coll_min*_sig_x,coll_max*_sig_x,\n",
    "                                            coll_min*_sig_y,coll_max*_sig_y,\n",
    "                                            coll_min*_sig_skew,coll_max*_sig_skew)\n",
    "\n",
    "        \n",
    "        # Initializing counts\n",
    "        #------------------------------------\n",
    "        if count_.sum() != 0:\n",
    "            hextiles.loc[(hex_x|hex_y|hex_s),f'counts:{name}'] = 0\n",
    "\n",
    "        # Show plane by plane:\n",
    "        #------------------------------------\n",
    "        hextiles.loc[hex_x,f'counts:{name}'] = (count_x&~count_y&~count_s).sum()\n",
    "        hextiles.loc[hex_y,f'counts:{name}'] = (~count_x&count_y&~count_s).sum()\n",
    "        hextiles.loc[hex_s,f'counts:{name}'] = (~count_x&~count_y&count_s).sum()\n",
    "\n",
    "        # Add cross planes:\n",
    "        #------------------------------------\n",
    "        hextiles.loc[hex_x,f'counts:{name}'] += (count_x&count_y&~count_s).sum()\n",
    "        hextiles.loc[hex_y,f'counts:{name}'] += (count_x&count_y&~count_s).sum()\n",
    "\n",
    "        hextiles.loc[hex_x,f'counts:{name}'] += (count_x&~count_y&count_s).sum()\n",
    "        hextiles.loc[hex_s,f'counts:{name}'] += (count_x&~count_y&count_s).sum()\n",
    "\n",
    "        hextiles.loc[hex_y,f'counts:{name}'] += (~count_x&count_y&count_s).sum()\n",
    "        hextiles.loc[hex_s,f'counts:{name}'] += (~count_x&count_y&count_s).sum()\n",
    "\n",
    "        # Cleaning counts\n",
    "        #------------------------------------\n",
    "        if count_.sum() == 0:\n",
    "            hextiles.loc[(hex_x|hex_y|hex_s),f'counts:{name}'] = np.nan\n",
    "\n",
    "\n",
    "        # # Show total\n",
    "        # #------------------------------------\n",
    "        # hextiles.loc[(hex_x|hex_y|hex_s),f'counts:{name}'] = count_x.sum()+count_y.sum()+count_s.sum()\n",
    "        # total += count_s.sum()\n",
    "        # print(total)\n",
    "\n",
    "    # hextiles[hextiles[f'counts:{name}'] == 0] = np.nan\n",
    "    hextiles['counts:active'] = hextiles['counts:0']\n",
    "\n",
    "    \n",
    "    # hextiles.dropna(inplace=True)\n",
    "    source    = bkmod.ColumnDataSource(hextiles)\n",
    "    nan_color = bkcolors.RGB(255,255,255,a=0)\n",
    "    cmap      = bktrfm.linear_cmap('counts:active', 'Plasma256', 0, 1500,nan_color=nan_color)\n",
    "    fig.hex_tile(q=\"q\", r=\"r\", size= _size, line_color=None, source=source,alpha=1,fill_color=cmap)\n",
    "\n",
    "\n",
    "    # color_bar = r.construct_color_bar(padding=0,\n",
    "    #                                   ticker=p.xaxis.ticker,\n",
    "    #                                   formatter=p.xaxis.formatter)\n",
    "\n",
    "    color_bar = bkmod.ColorBar(title='Counts',color_mapper=cmap['transform'])\n",
    "    fig.add_layout(color_bar, 'right')\n",
    "\n",
    "\n",
    "    # Axis and Legend\n",
    "    #=====================================\n",
    "\n",
    "    fig.xaxis.axis_label = 'x [m]'\n",
    "    fig.yaxis.axis_label = 'y [m]'\n",
    "    fig.legend.title     = r'Particles ID'\n",
    "    fig.legend.click_policy=\"hide\"\n",
    "    # fig.x_range=bkmod.Range1d(-6, 6)\n",
    "    # fig.y_range=bkmod.Range1d(-6, 6)\n",
    "    # fig.match_aspect=True\n",
    "\n",
    "    #=====================================\n",
    "\n",
    "    return fig\n",
    "\n",
    "fig = make_collimation_fig(data,title='Maximum excursion map',width=1000,height=700)\n",
    "# fig.aspect_ratio = 1\n",
    "bktools.set_aspect(fig , x_lim=(-3e-3,3e-3),y_lim=(-3e-3,3e-3), aspect=0.9)\n",
    "bk.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def update_coll(_df,coll_opening = 5):\n",
    "    \n",
    "    # Resetting values\n",
    "    #-----------------------------\n",
    "    _width  = _df['width'].unique()[0]\n",
    "    _height = _df['height'].unique()[0]\n",
    "    _df['xs']   = 6*[np.array([0,0,_width,_width])]\n",
    "    _df['ys']   = 6*[np.array([-_height/2,_height/2,_height/2,-_height/2])]\n",
    "\n",
    "    # Distributing colls on x-axis\n",
    "    #-----------------------------\n",
    "    _df['xs'] += coll_opening*_df['sigma']\n",
    "    _df.loc[_df.name.str.contains('left|bottom'),'xs']   *= -1\n",
    "\n",
    "    # Rotating according to angle\n",
    "    _x,_y  = np.stack(_df['xs']),np.stack(_df['ys'])\n",
    "    _angle = np.stack(_df['angle'].apply(lambda angle: list(np.repeat(angle,4))))\n",
    "    _x_rot = _x*np.cos(_angle) - _y*np.sin(_angle)\n",
    "    _y_rot = _x*np.sin(_angle) + _y*np.cos(_angle)\n",
    "\n",
    "\n",
    "    _df['xs'] = list(_x_rot)\n",
    "    _df['ys'] = list(_y_rot)\n",
    "\n",
    "    # Returning in mm\n",
    "    # _df['xs'] *= \n",
    "    # _df['ys'] *= \n",
    "\n",
    "    return _df\n",
    "\n",
    "\n",
    "def excursion_polygon(row):\n",
    "    # skew col : y = ax + b\n",
    "    skew_angle = 127.5\n",
    "    a = np.tan(np.deg2rad(skew_angle-90))\n",
    "    b = np.max([np.abs(row['skew_max']),np.abs(row['skew_min'])])/np.cos(np.deg2rad(skew_angle-90))\n",
    "\n",
    "    # skew col : y = ax - b, x = (y+b)/a\n",
    "    x1 = [row['x_max'],a*row['x_max'] - b]\n",
    "    x2 = [(row['y_min']+b)/a,row['y_min']]\n",
    "\n",
    "    # skew col : y = -ax - b, x = -(y+b)/a\n",
    "    x3 = [-(row['y_min']+b)/a,row['y_min']]\n",
    "    x4 = [row['x_min'],-a*row['x_min'] - b]\n",
    "\n",
    "    # skew col : y = ax + b, x = (y-b)/a\n",
    "    x5 = [row['x_min'],a*row['x_min'] + b]\n",
    "    x6 = [(row['y_max']-b)/a,row['y_max']]\n",
    "\n",
    "    # skew col : y = -ax + b, x = -(y-b)/a\n",
    "    x7 = [-(row['y_max']-b)/a,row['y_max']]\n",
    "    x8 = [row['x_max'],-a*row['x_max'] + b]\n",
    "\n",
    "    if x5[1]<x4[1]:\n",
    "        x4[1],x5[1] = x5[1],x4[1]\n",
    "    \n",
    "    if x8[1]<x1[1]:\n",
    "        x1[1],x8[1] = x8[1],x1[1]\n",
    "\n",
    "    return [x1[0],x2[0],x3[0],x4[0],x5[0],x6[0],x7[0],x8[0]], [x1[1],x2[1],x3[1],x4[1],x5[1],x6[1],x7[1],x8[1]]\n",
    "\n",
    "#=========================================================================================================================\n",
    "\n",
    "\n",
    "def lost_condition(x,y,x_skew,y_skew,coll_x,coll_y,coll_s):\n",
    "            return ((np.abs(x)>coll_x)|(np.abs(y)>coll_y)|(np.abs(x_skew)>coll_s)|(np.abs(y_skew)>coll_s))\n",
    "\n",
    "\n",
    "\n",
    "def condition_in_ring(x1,x2,y1,y2,s1,s2,collx1,collx2,colly1,colly2,colls1,colls2):\n",
    "    _out_ROI_min  =((np.abs(x1)>collx1)|(np.abs(x2)>collx1) | \n",
    "                    (np.abs(y1)>colly1)|(np.abs(y2)>colly1) | \n",
    "                    (np.abs(s1)>colls1)|(np.abs(s2)>colls1))\n",
    "    _out_ROI_max  =((np.abs(x1)>collx2)|(np.abs(x2)>collx2) | \n",
    "                    (np.abs(y1)>colly2)|(np.abs(y2)>colly2) | \n",
    "                    (np.abs(s1)>colls2)|(np.abs(s2)>colls2))\n",
    "    return ((_out_ROI_min) & (~_out_ROI_max))\n",
    "\n",
    "\n",
    "\n",
    "def make_ROI(x1,x2,y1,y2,s1,s2,collx1,collx2,colly1,colly2,colls1,colls2):\n",
    "    _out_ROI_min  =((np.abs(x1)>collx1)|(np.abs(x2)>collx1) | \n",
    "                    (np.abs(y1)>colly1)|(np.abs(y2)>colly1) | \n",
    "                    (np.abs(s1)>colls1)|(np.abs(s2)>colls1))\n",
    "    _out_ROI_max  =((np.abs(x1)>collx2)|(np.abs(x2)>collx2) | \n",
    "                    (np.abs(y1)>colly2)|(np.abs(y2)>colly2) | \n",
    "                    (np.abs(s1)>colls2)|(np.abs(s2)>colls2))\n",
    "    \n",
    "    ROI = ((_out_ROI_min) & (~_out_ROI_max))\n",
    "    # Splitting in 3 planes\n",
    "    ROI_x = ROI&((np.abs(x1)>collx1)|(np.abs(x2)>collx1))\n",
    "    ROI_y = ROI&((np.abs(y1)>colly1)|(np.abs(y2)>colly1))\n",
    "    ROI_s = ROI&(~ROI_x)&(~ROI_y)\n",
    "\n",
    "\n",
    "    return ROI_x,ROI_y,ROI_s\n",
    "\n",
    "def plane_condition(x1,x2,collx1,collx2):\n",
    "    _out_ROI_min  =((np.abs(x1)>collx1)|(np.abs(x2)>collx1)) \n",
    "    _out_ROI_max  =((np.abs(x1)>collx2)|(np.abs(x2)>collx2))\n",
    "    \n",
    "    ROI = ((_out_ROI_min) & (~_out_ROI_max))\n",
    "\n",
    "    return ROI\n",
    "\n",
    "def make_collimation_fig(data,title=None,width=2000,height=400):\n",
    "\n",
    "    # Creating Figure\n",
    "    #=====================================\n",
    "    fig = bk.figure(output_backend  = \"webgl\",\n",
    "                    height          = height, \n",
    "                    width           = width,\n",
    "                    title           = title, \n",
    "                    tools           = \"box_zoom,pan,reset,save,hover,wheel_zoom\",\n",
    "                    active_drag     = \"box_zoom\",\n",
    "                    active_scroll   = \"wheel_zoom\",\n",
    "                    toolbar_location= \"right\")\n",
    "\n",
    "\n",
    "    # Saving tools to tags\n",
    "    # _palette = bkpalettes.Viridis8\n",
    "    _palette = bkpalettes.Spectral10\n",
    "    fig.tags = [{str(type(t)).split('.')[-1].split('\\'')[0]:t for t in fig.tools},\n",
    "                {'palette':_palette}]\n",
    "    # fig.tags[0]['WheelZoomTool'].update(dimensions = 'height')\n",
    "    # fig.tags[0]['HoverTool'].update(tooltips = [('Variable', '$name'),('s [m]','$x{0}'),(f'Value', '$y'),('Element','@name')])\n",
    "    fig.tags[0]['HoverTool'].update(tooltips = [('Collimator [sigma_coll]','@opening'),('Count', '@{counts:active}')])\n",
    "\n",
    "    # Putting legend outside\n",
    "    # fig.add_layout(bkmod.Legend(), 'right')\n",
    "    #=====================================\n",
    "\n",
    "    coll_opening = 10\n",
    "    coll_alpha = np.deg2rad(127.5)\n",
    "    pipe_r     = cst.LHC_W_BEAM_SCREEN/2\n",
    "    coll_df    = pd.DataFrame({'name'   :  ['H_left','H_right','V_top','V_bottom','S_top','S_bottom'],\n",
    "                               'width'  :  pipe_r*np.ones(6),\n",
    "                               'height' :2*pipe_r*np.ones(6),\n",
    "                               'xs'     :6*[np.zeros(4)],\n",
    "                               'ys'     :6*[np.zeros(4)],\n",
    "                                'angle' :[0,0,np.pi/2,np.pi/2,coll_alpha,coll_alpha],\n",
    "                                'sigma' :[data.sig_x_coll,data.sig_x_coll,data.sig_y_coll,data.sig_y_coll,data.sig_skew_coll,data.sig_skew_coll]})\n",
    "\n",
    "        \n",
    "    coll_df = update_coll(coll_df,coll_opening=coll_opening)\n",
    "    source  = bkmod.ColumnDataSource(coll_df)\n",
    "    \n",
    "    fig.patches(xs='xs', ys='ys',alpha=1,color='gray',source=source)\n",
    "\n",
    "\n",
    "    # Crop at beam pipe\n",
    "    _x_pipe = np.array([-2*pipe_r] + list(np.linspace(-pipe_r,pipe_r,200)) + [2*pipe_r])\n",
    "    _y_pipe = np.sqrt(pipe_r**2 - _x_pipe**2)\n",
    "    _y_pipe[np.abs(_x_pipe)>pipe_r] = 0\n",
    "    fig.varea(x=_x_pipe,y1=2*pipe_r*np.ones(len(_x_pipe)),y2=_y_pipe  ,color='white',alpha=1)\n",
    "    fig.varea(x=_x_pipe,y2=-2*pipe_r*np.ones(len(_x_pipe)),y1=-_y_pipe,color='white',alpha=1)\n",
    "\n",
    "\n",
    "        # Creating Hextiles\n",
    "    #=====================================\n",
    "    coll_values = np.linspace(0,10,50)\n",
    "    n_bins      = 300\n",
    "    coll_sig = np.max([data.sig_x_coll,data.sig_y_coll])\n",
    "    XX,YY    = np.meshgrid(np.linspace(-coll_values[-1]*coll_sig,coll_values[-1]*coll_sig,n_bins),\n",
    "                            np.linspace(-coll_values[-1]*coll_sig,coll_values[-1]*coll_sig,n_bins))\n",
    "\n",
    "    _size        = np.min(np.abs(np.diff(XX.flatten())))\n",
    "    _orientation = 'pointytop'\n",
    "\n",
    "    hextiles = bkhex.hexbin(XX.flatten(), YY.flatten(), _size)\n",
    "    _x,_y    = bkhex.axial_to_cartesian(hextiles.q,hextiles.r,size=_size,orientation=_orientation)\n",
    "    theta_unskew= -np.deg2rad(127.5)\n",
    "    _x_skew       = _x*np.cos(theta_unskew) - _y*np.sin(theta_unskew)\n",
    "    _y_skew       = _x*np.cos(-theta_unskew) - _y*np.sin(-theta_unskew)\n",
    "    hextiles.insert(0,'x',_x)\n",
    "    hextiles.insert(1,'y',_y)\n",
    "    hextiles.insert(2,'x_skew',_x_skew)\n",
    "    hextiles.insert(3,'y_skew',_y_skew)\n",
    "    hextiles.insert(4,'opening',np.nan)\n",
    "    hextiles.counts = np.nan\n",
    "    hextiles.rename(columns={'counts':'counts:active'},inplace=True)\n",
    "    #=====================================\n",
    "\n",
    "\n",
    "\n",
    "    _sig_x    = data.sig_x_coll\n",
    "    _sig_y    = data.sig_y_coll\n",
    "    _sig_skew = data.sig_skew_coll\n",
    "    # Looping over chunks\n",
    "\n",
    "    # name  = 0\n",
    "    # group = data.data.groupby('Chunk ID').get_group(name)\n",
    "    # group = group.set_index('particle').loc[[10]]\n",
    "    \n",
    "\n",
    "    for name,group in data.data.groupby('Chunk ID'):\n",
    "        hextiles.insert(len(hextiles.columns),f'counts:{name}',np.nan)\n",
    "        for coll_min,coll_max in zip(coll_values[:-1],coll_values[1:]):\n",
    "            \n",
    "            # Identifying Hex in ROI\n",
    "            \n",
    "            hex_x,hex_y,hex_s  = make_ROI( hextiles['x'],hextiles['x'],\n",
    "                                            hextiles['y'],hextiles['y'],\n",
    "                                            hextiles['x_skew'],hextiles['y_skew'],\n",
    "                                            coll_min*_sig_x,coll_max*_sig_x,\n",
    "                                            coll_min*_sig_y,coll_max*_sig_y,\n",
    "                                            coll_min*_sig_skew,coll_max*_sig_skew)\n",
    "            hextiles.loc[(hex_x|hex_y|hex_s),f'opening'] = np.mean([coll_min,coll_max])\n",
    "\n",
    "\n",
    "            # Counts per collimators\n",
    "            #------------------------------------\n",
    "            count_x = plane_condition(group['x_min'],group['x_max'],coll_min*_sig_x,coll_max*_sig_x)\n",
    "            count_y = plane_condition(group['y_min'],group['y_max'],coll_min*_sig_y,coll_max*_sig_y)\n",
    "            count_s = plane_condition(group['skew_min'],group['skew_max'],coll_min*_sig_skew,coll_max*_sig_skew)\n",
    "            \n",
    "            # Initializing counts\n",
    "            #------------------------------------\n",
    "            if count_x.sum()+count_y.sum()+count_s.sum() != 0:\n",
    "                hextiles.loc[(hex_x|hex_y|hex_s),f'counts:{name}'] = 0\n",
    "\n",
    "            # Show plane by plane:\n",
    "            #------------------------------------\n",
    "            hextiles.loc[hex_x,f'counts:{name}'] = count_x.sum()\n",
    "            hextiles.loc[hex_y,f'counts:{name}'] = count_y.sum()\n",
    "            hextiles.loc[hex_s,f'counts:{name}'] = count_s.sum()\n",
    "\n",
    "            # Cleaning counts\n",
    "            #------------------------------------\n",
    "            if count_x.sum()+count_y.sum()+count_s.sum() == 0:\n",
    "                hextiles.loc[(hex_x|hex_y|hex_s),f'counts:{name}'] = np.nan\n",
    "\n",
    "\n",
    "    hextiles['counts:active'] = hextiles['counts:0']\n",
    "\n",
    "    data_col  = [col for col in hextiles.columns if 'counts:' in col]\n",
    "    max_value = np.max(hextiles[data_col].sum(axis=1)) \n",
    "    source    = bkmod.ColumnDataSource(hextiles[['q','r','opening']+data_col])\n",
    "    nan_color = bkcolors.RGB(255,255,255,a=0)\n",
    "    # cmap      = bktrfm.linear_cmap('counts:active', 'Plasma256', 0, 1500,nan_color=nan_color)\n",
    "    cmap      = bktrfm.log_cmap('counts:active', 'Magma256', 1, max_value,nan_color=nan_color)\n",
    "    fig.hex_tile(q=\"q\", r=\"r\", size= _size, line_color=None, source=source,alpha=1,fill_color=cmap)\n",
    "\n",
    "\n",
    "    color_bar = bkmod.ColorBar(title='Counts',color_mapper=cmap['transform'])\n",
    "    fig.add_layout(color_bar, 'right')\n",
    "\n",
    "\n",
    "    # Axis and Legend\n",
    "    #=====================================\n",
    "\n",
    "    fig.xaxis.axis_label = 'x [m]'\n",
    "    fig.yaxis.axis_label = 'y [m]'\n",
    "    # fig.legend.title     = r'Particles ID'\n",
    "    # fig.legend.click_policy=\"hide\"\n",
    "    # fig.x_range=bkmod.Range1d(-6, 6)\n",
    "    # fig.y_range=bkmod.Range1d(-6, 6)\n",
    "    # fig.match_aspect=True\n",
    "\n",
    "    #=====================================\n",
    "\n",
    "    return fig\n",
    "\n",
    "fig = make_collimation_fig(data,title='Maximum excursion map',width=1000,height=700)\n",
    "# fig.aspect_ratio = 1\n",
    "bktools.set_aspect(fig , x_lim=(-3e-3,3e-3),y_lim=(-3e-3,3e-3), aspect=0.9)\n",
    "bk.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.set_index('particle').loc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lost_condition(x,y,x_skew,y_skew,coll_x,coll_y,coll_s):\n",
    "            return ((np.abs(x)>coll_x)|(np.abs(y)>coll_y)|(np.abs(x_skew)>coll_s)|(np.abs(y_skew)>coll_s))\n",
    "\n",
    "\n",
    "# Creating Hextiles\n",
    "#=====================================\n",
    "coll_values = np.linspace(0,10,50)\n",
    "coll_sig = np.max([data.sig_x_coll,data.sig_y_coll])\n",
    "XX,YY    = np.meshgrid(np.linspace(-coll_values[-1]*coll_sig,coll_values[-1]*coll_sig,300),\n",
    "                        np.linspace(-coll_values[-1]*coll_sig,coll_values[-1]*coll_sig,300))\n",
    "\n",
    "_size        = np.min(np.abs(np.diff(XX.flatten())))\n",
    "_orientation = 'pointytop'\n",
    "\n",
    "hextiles = bkhex.hexbin(XX.flatten(), YY.flatten(), _size)\n",
    "_x,_y    = bkhex.axial_to_cartesian(hextiles.q,hextiles.r,size=_size,orientation=_orientation)\n",
    "theta_unskew= -np.deg2rad(127.5)\n",
    "_x_skew       = _x*np.cos(theta_unskew) - _y*np.sin(theta_unskew)\n",
    "_y_skew       = _x*np.cos(-theta_unskew) - _y*np.sin(-theta_unskew)\n",
    "hextiles.insert(0,'x',_x)\n",
    "hextiles.insert(1,'y',_y)\n",
    "hextiles.insert(2,'x_skew',_x_skew)\n",
    "hextiles.insert(3,'y_skew',_y_skew)\n",
    "hextiles.insert(4,'opening',np.nan)\n",
    "hextiles.counts = np.nan\n",
    "hextiles.rename(columns={'counts':'counts:active'},inplace=True)\n",
    "#=====================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_ROI(x1,x2,y1,y2,s1,s2,collx1,collx2,colly1,colly2,colls1,colls2,force_normalisation = False):\n",
    "    _out_ROI_min  =((np.abs(x1)>collx1)|(np.abs(x2)>collx1) | \n",
    "                    (np.abs(y1)>colly1)|(np.abs(y2)>colly1) | \n",
    "                    (np.abs(s1)>colls1)|(np.abs(s2)>colls1))\n",
    "    _out_ROI_max  =((np.abs(x1)>collx2)|(np.abs(x2)>collx2) | \n",
    "                    (np.abs(y1)>colly2)|(np.abs(y2)>colly2) | \n",
    "                    (np.abs(s1)>colls2)|(np.abs(s2)>colls2))\n",
    "    \n",
    "    ROI = ((_out_ROI_min) & (~_out_ROI_max))\n",
    "    # Splitting in 3 planes\n",
    "    ROI_x = ROI&((np.abs(x1)>collx1)|(np.abs(x2)>collx1))\n",
    "    ROI_y = ROI&((np.abs(y1)>colly1)|(np.abs(y2)>colly1))\n",
    "    ROI_s = ROI&((np.abs(s1)>colls1)|(np.abs(s2)>colls1))\n",
    "    if force_normalisation:\n",
    "        ROI_s = ROI&(~ROI_x)&(~ROI_y)\n",
    "    # print('lol')\n",
    "    return ROI,ROI_x,ROI_y,ROI_s\n",
    "\n",
    "_sig_x    = data.sig_x_coll\n",
    "_sig_y    = data.sig_y_coll\n",
    "_sig_skew = data.sig_skew_coll\n",
    "# Looping over chunks\n",
    "\n",
    "name  = 22\n",
    "group = data.data.groupby('Chunk ID').get_group(name)\n",
    "hextiles.insert(len(hextiles.columns),f'counts:{name}',np.nan)\n",
    "\n",
    "for coll_min,coll_max in zip(coll_values[:-1],coll_values[1:]):\n",
    "    \n",
    "    # Identifying Hex in ROI\n",
    "    \n",
    "    hex_tot,hex_x,hex_y,hex_s  = make_ROI( hextiles['x'],hextiles['x'],\n",
    "                                    hextiles['y'],hextiles['y'],\n",
    "                                    hextiles['x_skew'],hextiles['y_skew'],\n",
    "                                    coll_min*_sig_x,coll_max*_sig_x,\n",
    "                                    coll_min*_sig_y,coll_max*_sig_y,\n",
    "                                    coll_min*_sig_skew,coll_max*_sig_skew)\n",
    "    hextiles.loc[(hex_x|hex_y|hex_s),f'opening'] = np.mean([coll_min,coll_max])\n",
    "\n",
    "\n",
    "    # Counts per collimators\n",
    "    #------------------------------------\n",
    "    count_tot,count_x,count_y,count_s = make_ROI( group['x_max'],group['x_min'],\n",
    "                                        group['y_max'],group['y_min'],\n",
    "                                        group['skew_max'],group['skew_min'],\n",
    "                                        coll_min*_sig_x,coll_max*_sig_x,\n",
    "                                        coll_min*_sig_y,coll_max*_sig_y,\n",
    "                                        coll_min*_sig_skew,coll_max*_sig_skew)\n",
    "    print(count_x.sum(),count_y.sum(),count_s.sum())\n",
    "    hextiles.loc[hex_x,f'counts:{name}'] = count_x.sum()\n",
    "    hextiles.loc[hex_y,f'counts:{name}'] = count_y.sum()\n",
    "    hextiles.loc[hex_s,f'counts:{name}'] = count_s.sum()\n",
    "\n",
    "    # if count_x.sum()>10:\n",
    "    #       break\n",
    "\n",
    "# hextiles['counts:active'] = hextiles['counts:0']\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "# for name,group in J_df.groupby('Chunk ID'):\n",
    "#         # Forcing corner values to have same grid.\n",
    "#         _hex = bkhex.hexbin(np.array(list(group['Jx/emitt']) + [J_df['Jx/emitt'].min(),J_df['Jx/emitt'].max()]),\n",
    "#                             np.array(list(group['Jy/emitt']) + [J_df['Jy/emitt'].min(),J_df['Jy/emitt'].max()]),\n",
    "#                             size=_size,orientation=_orientation)\n",
    "\n",
    "#         # Removing corner values\n",
    "#         _hex = _hex[1:-1]\n",
    "\n",
    "#         # Adding chunk ID\n",
    "#         hextiles_template.insert(name+1,f'counts:{name}',_hex.set_index(['q','r'])['counts'])\n",
    "\n",
    "\n",
    "\n",
    "# hextiles_template.reset_index(inplace=True)\n",
    "# hextiles_template['counts:active'] = hextiles_template['counts:0']\n",
    "\n",
    "\n",
    "# coll_values = np.linspace(0,10,50)\n",
    "# turn_list   = list(data.data.groupby('start_at_turn').groups.keys())\n",
    "# selected_turn = turn_list[16]\n",
    "# for coll_min,coll_max in zip(coll_values[:-1],coll_values[1:]):\n",
    "\n",
    "#     try:\n",
    "#         counts = (data.compute_intensity(coll_opening=coll_max,at_turn = selected_turn)['count']- data.compute_intensity(coll_opening=coll_min,at_turn = selected_turn)['count']).values[-1]\n",
    "#     except:\n",
    "#         counts = np.nan\n",
    "    \n",
    "#     _out_ROI_max = lost_condition(hextiles['x'],hextiles['y'],hextiles['x_skew'],hextiles['y_skew'],coll_max*data.sig_x_coll,coll_max*data.sig_y_coll,coll_max*data.sig_skew_coll)\n",
    "#     _out_ROI_min = lost_condition(hextiles['x'],hextiles['y'],hextiles['x_skew'],hextiles['y_skew'],coll_min*data.sig_x_coll,coll_min*data.sig_y_coll,coll_min*data.sig_skew_coll)\n",
    "#     _out_ROI = ((_out_ROI_min) & (~_out_ROI_max))\n",
    "# #         \n",
    "#     hextiles.loc[_out_ROI,'counts'] = counts\n",
    "#     hextiles.loc[_out_ROI,'opening'] = np.mean([coll_min,coll_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_ROI(x1,x2,y1,y2,s1,s2,collx1,collx2,colly1,colly2,colls1,colls2,force_normalisation = False):\n",
    "    _out_ROI_min  =((np.abs(x1)>collx1)|(np.abs(x2)>collx1) | \n",
    "                    (np.abs(y1)>colly1)|(np.abs(y2)>colly1) | \n",
    "                    (np.abs(s1)>colls1)|(np.abs(s2)>colls1))\n",
    "    _out_ROI_max  =((np.abs(x1)>collx2)|(np.abs(x2)>collx2) | \n",
    "                    (np.abs(y1)>colly2)|(np.abs(y2)>colly2) | \n",
    "                    (np.abs(s1)>colls2)|(np.abs(s2)>colls2))\n",
    "    \n",
    "    ROI = ((_out_ROI_min) & (~_out_ROI_max))\n",
    "    # Splitting in 3 planes\n",
    "    ROI_x = ROI&((np.abs(x1)>collx1)|(np.abs(x2)>collx1))\n",
    "    ROI_y = ROI&((np.abs(y1)>colly1)|(np.abs(y2)>colly1))\n",
    "    ROI_s = ROI&((np.abs(s1)>colls1)|(np.abs(s2)>colls1))\n",
    "    if force_normalisation:\n",
    "        ROI_s = ROI&(~ROI_x)&(~ROI_y)\n",
    "    # print('lol')\n",
    "    return ROI,ROI_x,ROI_y,ROI_s\n",
    "\n",
    "    \n",
    "total = 0\n",
    "for coll_min,coll_max in zip(coll_values[:-1],coll_values[1:]):\n",
    "    # y_cond_min = (np.abs(group['y_max'])>coll_min*data.sig_y_coll)|(np.abs(group['y_min'])>coll_min*data.sig_y_coll)\n",
    "    # y_cond_max = (np.abs(group['y_max'])>coll_max*data.sig_y_coll)|(np.abs(group['y_min'])>coll_max*data.sig_y_coll)\n",
    "    # y_ring = y_cond_min&(~y_cond_max)\n",
    "    # total += y_ring.sum()\n",
    "    # print(y_cond_min.sum(),y_cond_max.sum(),y_ring.sum(),total)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    count_tot,count_x,count_y,count_s = make_ROI( group['x_max'],group['x_min'],\n",
    "                                        group['y_max'],group['y_min'],\n",
    "                                        group['skew_max'],group['skew_min'],\n",
    "                                        coll_min*_sig_x,coll_max*_sig_x,\n",
    "                                        coll_min*_sig_y,coll_max*_sig_y,\n",
    "                                        coll_min*_sig_skew,coll_max*_sig_skew)\n",
    "    total += count_y.sum()\n",
    "    print(count_y.sum(),total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(count_tot),sum(count_x),sum(count_y),sum(count_s),sum(count_x)+sum(count_y)+sum(count_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_min = 3\n",
    "coll_max = 3.1\n",
    "make_ROI( group['x_max'],group['x_min'],\n",
    "                                        group['y_max'],group['y_min'],\n",
    "                                        group['skew_max'],group['skew_min'],\n",
    "                                        coll_min*_sig_x,coll_max*_sig_x,\n",
    "                                        coll_min*_sig_y,coll_max*_sig_y,\n",
    "                                        coll_min*_sig_skew,coll_max*_sig_skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(count_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_df = {}\n",
    "coll_values = np.linspace(0,10,50)\n",
    "for coll_val in  coll_values:\n",
    "    try:\n",
    "        intensity_df[coll_val] = data.compute_intensity(coll_opening=coll_val).set_index('Chunk ID')[['count','survived']][1:]\n",
    "    except:\n",
    "        intensity_df[coll_val] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_df = {}\n",
    "coll_values = np.linspace(0,10,50)\n",
    "for coll_val in  coll_values:\n",
    "    try:\n",
    "        intensity_df[coll_val] = data.compute_intensity(coll_opening=coll_val,find_plane=True).set_index('Chunk ID')[['count','survived']][1:]\n",
    "    except:\n",
    "        intensity_df[coll_val] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data.compute_intensity(coll_opening=coll_max).set_index('Chunk ID')['count']- data.compute_intensity(coll_opening=coll_min,at_turn = selected_turn)['count']).values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = data\n",
    "coll_opening = 5\n",
    "from_df='_data'\n",
    "at_turn = None\n",
    "\n",
    "\n",
    "_sigx = np.sqrt(self.betx*3.5e-6/self.particle_on_co.gamma0[0])\n",
    "_sigy = np.sqrt(self.bety*3.5e-6/self.particle_on_co.gamma0[0])\n",
    "# Ellipse in polar: r(alpha) = sqrt((a*cos(alpha))^2 + (b*sin(alpha))^2)\n",
    "_alpha   = np.deg2rad(127.5)\n",
    "_sigskew = np.sqrt((_sigx*np.cos(_alpha))**2 + (_sigy*np.sin(_alpha))**2)\n",
    "\n",
    "# Collimator opening\n",
    "coll_x = coll_opening*_sigx\n",
    "coll_y = coll_opening*_sigy\n",
    "coll_s = coll_opening*_sigskew\n",
    "\n",
    "\n",
    "\n",
    "def plane_lost(df):\n",
    "    _plane  = pd.Series('',index=df.x_min.index)\n",
    "    idx_x   = _plane.index[(np.abs(df.x_min)>coll_x)|(np.abs(df.x_max)>coll_x)]\n",
    "    idx_y   = _plane.index[(np.abs(df.y_min)>coll_y)|(np.abs(df.y_max)>coll_y)]\n",
    "    idx_skew= _plane.index[(np.abs(df.skew_min)>coll_s)|(np.abs(df.skew_max)>coll_s)]\n",
    "\n",
    "    _plane.loc[idx_x] += 'x'\n",
    "    _plane.loc[idx_y] += 'y'\n",
    "    _plane.loc[idx_skew] += 's'\n",
    "\n",
    "    return _plane\n",
    "\n",
    "\n",
    "# Keep columns\n",
    "coordinates = ['x','y','skew']\n",
    "keep_cols   = [f'{i}_min' for i in coordinates] + [f'{i}_max' for i in coordinates]\n",
    "keep_cols   = ['Chunk ID','particle','start_at_turn','stop_at_turn'] + keep_cols\n",
    "\n",
    "if from_df == '_data':\n",
    "    group  = self.data[keep_cols]\n",
    "    if at_turn is not None:\n",
    "        group  = group[group.start_at_turn <= at_turn]\n",
    "elif from_df == '_checkpoint':\n",
    "    #TODO\n",
    "    pass\n",
    "elif from_df == '_df':\n",
    "    #TODO\n",
    "    pass\n",
    "\n",
    "\n",
    "_plane_lost  = plane_lost(group)\n",
    "_lost        = _plane_lost.apply(lambda plane_str: len(plane_str)>0)\n",
    "idx_lost     = group.index[_lost]\n",
    "idx_survived = group.index[~_lost]\n",
    "\n",
    "# New columns\n",
    "\n",
    "group.insert(0,'beyond_coll',False)\n",
    "group.insert(0,'lost',False)\n",
    "\n",
    "\n",
    "# Finding lost particles\n",
    "group.loc[idx_lost,'beyond_coll'] = True\n",
    "group.loc[:,'lost'] = group.groupby('particle').beyond_coll.cumsum().astype(bool)\n",
    "\n",
    "\n",
    "# Finding lost plane:\n",
    "group.insert(0,'plane',_plane_lost)\n",
    "group.loc[_lost,'plane'] += '|'\n",
    "_plane_df = group[['particle','plane']]\n",
    "_plane_result = _plane_df.groupby('particle')['plane'].apply(pd.Series.cumsum).apply(lambda _str: _str.split('|')[0]).to_frame()\n",
    "_plane_result.insert(0,'index',_plane_result.index.get_level_values(1))\n",
    "_plane_result = _plane_result.sort_values('index').set_index('index')\n",
    "group.loc[:,'plane'] = _plane_result['plane']\n",
    "\n",
    "intensity = group[~group.lost].groupby('start_at_turn').count().particle\n",
    "intensity = group[~group.lost].groupby('start_at_turn').count().particle.to_frame()\n",
    "intensity.insert(0,'stop_at_turn',group.groupby('start_at_turn').stop_at_turn.max())\n",
    "intensity.insert(1,'Chunk ID',group.groupby('start_at_turn')['Chunk ID'].max())\n",
    "intensity.reset_index(drop=False,inplace=True)\n",
    "intensity.rename(columns={'particle':'count'},inplace=True)\n",
    "\n",
    "\n",
    "survived  = group[~group.lost].groupby('start_at_turn').apply(lambda group: list(group.particle.values))\n",
    "lost      = group[group.lost].groupby('start_at_turn').apply(lambda group: list(group.particle.values))\n",
    "plane     = group[group.lost].groupby('start_at_turn').apply(lambda group: list(group.plane.values))\n",
    "intensity.insert(3,'survived',survived.values)\n",
    "intensity.insert(4,'lost',lost.values)\n",
    "intensity.insert(5,'plane',plane.values)\n",
    "\n",
    "starting_point = pd.DataFrame({'Chunk ID':[-1],'start_at_turn':[-1],'stop_at_turn':[0],'count':[len(group.particle.unique())],'survived':[list(group.particle.unique())]})\n",
    "intensity      = pd.concat([starting_point,intensity]).reset_index(drop=True)\n",
    "intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2279+17721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(intensity.loc[23]['plane']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost      = group[group.lost].groupby('start_at_turn').apply(lambda group: list(group.particle.values))\n",
    "plane     = group[group.lost].groupby('start_at_turn').apply(lambda group: list(group.plane.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.groupby('particle')['plane'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.groupby('particle')['plane'].apply(pd.Series.cumsum).apply(lambda _str: _str.split('|')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.set_index(['particle','start_at_turn']).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.groupby('particle').beyond_coll.cumsum()#.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(['1','2','3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.groupby('particle').apply(lambda part: sum(part['plane']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test.loc[_lost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.x_min\n",
    "\n",
    "pd.Series(np.nan,index=group.x_min.index).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.x_min>coll_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.x_max.copy()*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity['lost'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.compute_intensity(coll_opening=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data.groupby('start_at_turn')['Chunk ID'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.checkpoint[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data.checkpoint_sig[:2][['x_sig']]**2+data.checkpoint_sig[:2][['px_sig']]**2)*data.sig_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x/sig_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_JxJy_fig(data,title=None,width=2000,height=400):\n",
    "\n",
    "    # Creating Figure\n",
    "    #=====================================\n",
    "    fig = bk.figure(output_backend  = \"webgl\",\n",
    "                    height          = height, \n",
    "                    width           = width,\n",
    "                    title           = title, \n",
    "                    tools           = \"box_zoom,pan,reset,save,hover,wheel_zoom\",\n",
    "                    active_drag     = \"pan\",\n",
    "                    active_scroll   = \"wheel_zoom\",\n",
    "                    toolbar_location= \"right\")\n",
    "\n",
    "\n",
    "    # Saving tools to tags\n",
    "    # _palette = bkpalettes.Viridis8\n",
    "    _palette = bkpalettes.Spectral10\n",
    "    fig.tags = [{str(type(t)).split('.')[-1].split('\\'')[0]:t for t in fig.tools},\n",
    "                {'palette':_palette}]\n",
    "    # fig.tags[0]['WheelZoomTool'].update(dimensions = 'height')\n",
    "    # fig.tags[0]['HoverTool'].update(tooltips = [('Variable', '$name'),('s [m]','$x{0}'),(f'Value', '$y'),('Element','@name')])\n",
    "    fig.tags[0]['HoverTool'].update(tooltips = [('Collimator [sigma_coll]','@opening'),('Count', '@counts')])\n",
    "\n",
    "    # Putting legend outside\n",
    "    # fig.add_layout(bkmod.Legend(), 'right')\n",
    "    #=====================================\n",
    "\n",
    "    J_df = data.checkpoint.groupby('Chunk ID').get_group(1)[['BUNCH','Chunk ID','turn','particle']]\n",
    "    J_df.insert(4,'Jx/emitt',1/2 * (data.checkpoint_sig.x_sig**2 + data.checkpoint_sig.px_sig**2))\n",
    "    J_df.insert(5,'Jy/emitt',1/2 * (data.checkpoint_sig.y_sig**2 + data.checkpoint_sig.py_sig**2))\n",
    "    J_df.dropna(inplace=True)\n",
    "\n",
    "  \n",
    "    # coll_sig = np.max([data.sig_x_coll,data.sig_y_coll])\n",
    "    coll_max = 10\n",
    "    _x_dummy = np.linspace(0,10**2/2 ,300)\n",
    "\n",
    "\n",
    "    _size        = np.min(np.abs(np.diff(_x_dummy)))\n",
    "    _orientation = 'pointytop'\n",
    "\n",
    "    hextiles = bkhex.hexbin(J_df['Jx/emitt'],J_df['Jy/emitt'], _size)\n",
    "\n",
    "\n",
    "\n",
    "    source = hextiles\n",
    "    cmap   = bktrfm.linear_cmap('counts', 'Viridis256', 0, max(source.counts))\n",
    "    fig.hex_tile(q=\"q\", r=\"r\", size= _size, line_color=None, source=source,alpha=1,fill_color=cmap)\n",
    "\n",
    "    fig.hspan(y=[0], line_width=[2], line_color=\"black\")\n",
    "    fig.vspan(x=[0], line_width=[2], line_color=\"black\")\n",
    "\n",
    "    # source = bkmod.ColumnDataSource(J_df)\n",
    "    # fig.scatter('Jx/emitt','Jy/emitt', alpha=0.6, source=source)\n",
    "\n",
    "\n",
    "    color_bar = bkmod.ColorBar(title='Counts',color_mapper=cmap['transform'])\n",
    "    fig.add_layout(color_bar, 'right')\n",
    "\n",
    "\n",
    "    # Axis and Legend\n",
    "    #=====================================\n",
    "\n",
    "    fig.xaxis.axis_label = 'Jx/emitt'\n",
    "    fig.yaxis.axis_label = 'Jy/emitt'\n",
    "\n",
    "\n",
    "    #=====================================\n",
    "\n",
    "    return fig\n",
    "\n",
    "fig = make_JxJy_fig(data,title='(Jx,Jy) Distribution',width=1000,height=700)\n",
    "# fig.aspect_ratio = 1\n",
    "bktools.set_aspect(fig , x_lim=(-5,65),y_lim=(-5,50), aspect=0.9)\n",
    "bk.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.n_parts//"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_slider(data,title=None,width=2000,height=400):\n",
    "\n",
    "    # Creating Figure\n",
    "    #=====================================\n",
    "    fig = bk.figure(output_backend  = \"webgl\",\n",
    "                    height          = height, \n",
    "                    width           = width,\n",
    "                    title           = title, \n",
    "                    tools           = \"box_zoom,pan,reset,save,hover,wheel_zoom\",\n",
    "                    active_drag     = \"pan\",\n",
    "                    active_scroll   = \"wheel_zoom\",\n",
    "                    toolbar_location= \"right\")\n",
    "\n",
    "\n",
    "    # Saving tools to tags\n",
    "    # _palette = bkpalettes.Viridis8\n",
    "    _palette = bkpalettes.Spectral10\n",
    "    fig.tags = [{str(type(t)).split('.')[-1].split('\\'')[0]:t for t in fig.tools},\n",
    "                {'palette':_palette}]\n",
    "    # fig.tags[0]['WheelZoomTool'].update(dimensions = 'height')\n",
    "    # fig.tags[0]['HoverTool'].update(tooltips = [('Variable', '$name'),('s [m]','$x{0}'),(f'Value', '$y'),('Element','@name')])\n",
    "    fig.tags[0]['HoverTool'].update(tooltips = [('Collimator [sigma_coll]','@opening'),('Count', '@counts')])\n",
    "\n",
    "    # Putting legend outside\n",
    "    # fig.add_layout(bkmod.Legend(), 'right')\n",
    "    #=====================================\n",
    "\n",
    "\n",
    "    chunk_df = data.data[['Chunk ID','start_at_turn','stop_at_turn']].groupby('Chunk ID').mean()\n",
    "    chunk_df.insert(0,'x',(chunk_df['stop_at_turn']+chunk_df['start_at_turn'])/2)\n",
    "\n",
    "    to_source = bktools.source_from_groupby(chunk_df,by='Chunk ID',columns = ['x'])\n",
    "    # to_source\n",
    "    \n",
    "    to_source.insert(0,'width',(chunk_df['stop_at_turn']-chunk_df['start_at_turn']).max())\n",
    "    to_source.insert(1,'height',1)\n",
    "    to_source.insert(2,'y',0.5)\n",
    "\n",
    "        \n",
    "    # source = bkto_source\n",
    "    source_chunk  = bkmod.ColumnDataSource(to_source)\n",
    "    \n",
    "    fig.rect(x='x:active', y='y', width='width', height='height',alpha=0.5,source=source_chunk)\n",
    "\n",
    "\n",
    "    for coll_opening,color in zip([3,4,5,6,7,8,9,10][::-1],fig.tags[1]['palette']):\n",
    "        # Creating source\n",
    "        #=====================================\n",
    "        intensity_df = data.compute_intensity(coll_opening=coll_opening)\n",
    "        intensity_df = intensity_df[1:]\n",
    "        intensity_df.insert(3,'Norm. Count',np.abs(intensity_df['count'])/intensity_df.loc[1,'count'])\n",
    "        source       = bkmod.ColumnDataSource(intensity_df[['start_at_turn','Norm. Count']])\n",
    "        #=====================================\n",
    "\n",
    "\n",
    "        # Plotting\n",
    "        #=====================================\n",
    "        legend_opening = str(coll_opening).ljust(4-len(str(coll_opening)))\n",
    "        fig.step(x='start_at_turn',y='Norm. Count', source=source,legend_label=f'{legend_opening} _coll, [I(0) = {str(intensity_df.loc[1,\"count\"]).ljust(7)} p+]',line_width=2,color=color)\n",
    "        #=====================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    padding =  100\n",
    "    chunk_slider = bkmod.Slider(start=data.data['Chunk ID'].min(), end=data.data['Chunk ID'].max(), value=0, step=1, title=\"Chunk ID\",width = width-2*padding,margin=[0,100])\n",
    "    fig.min_border_right = padding\n",
    "    fig.min_border_left  = padding\n",
    "\n",
    "\n",
    "    callback = bkmod.callbacks.CustomJS(args=dict(slider = chunk_slider,source = source_chunk), code=\"\"\"\n",
    "                //=========================================================\n",
    "                source.data['x:active'] = source.data['x:'+slider.value.toString()];\n",
    "                source.change.emit()\n",
    "                //=========================================================\"\"\")\n",
    "\n",
    "    chunk_slider.js_on_change('value', callback)\n",
    "\n",
    "\n",
    "    return fig,chunk_slider\n",
    "\n",
    "\n",
    "\n",
    "fig,chunk_slider= test_slider(data,title='(Jx,Jy) Distribution',width=1000,height=700)\n",
    "# fig.aspect_ratio = 1\n",
    "# bktools.set_aspect(fig , x_lim=(-5,65),y_lim=(-5,50), aspect=0.9)\n",
    "bk.show(bklay.column(fig,chunk_slider))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_slider = bkmod.Slider(start=data.data['Chunk ID'].min(), end=data.data['Chunk ID'].max(), value=0, step=1, title=\"Chunk ID\",width = 100,margin=[0,100])\n",
    "\n",
    "\n",
    "def make_phasespace_fig(df,xy,slider,title=None,width=2000,height=400):\n",
    "\n",
    "    # Creating Figure\n",
    "    #=====================================\n",
    "    fig = bk.figure(output_backend  = \"webgl\",\n",
    "                    height          = height, \n",
    "                    width           = width,\n",
    "                    title           = title, \n",
    "                    tools           = \"box_zoom,pan,reset,save,hover,wheel_zoom,crosshair\",\n",
    "                    active_drag     = \"box_zoom\",\n",
    "                    active_scroll   = \"wheel_zoom\",\n",
    "                    active_inspect  = None,\n",
    "                    toolbar_location= \"right\")\n",
    "\n",
    "\n",
    "    # Saving tools to tags\n",
    "    _palette = bkpalettes.Spectral10\n",
    "    fig.tags = [{str(type(t)).split('.')[-1].split('\\'')[0]:t for t in fig.tools},\n",
    "                {'palette':_palette}]\n",
    "    fig.tags[0]['HoverTool'].update(tooltips = [('Particle', '$index'),(f'Coordinates', '($x,$y)')])\n",
    "    #=====================================\n",
    "\n",
    "\n",
    "    # Creating source\n",
    "    #=====================================\n",
    "    x,y = xy\n",
    "    to_source = bktools.source_from_groupby(df,by='Chunk ID',columns = [x,y])\n",
    "    to_source.insert(0,'particle',df.groupby('Chunk ID').get_group(0).particle)\n",
    "    source = bkmod.ColumnDataSource(to_source)\n",
    "\n",
    "    #=====================================\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    #=====================================\n",
    "    fig.scatter(f'{x}:active',f'{y}:active', alpha=0.3, source=source)\n",
    "    #=====================================\n",
    "\n",
    "    # Adding slider callback\n",
    "    #=====================================\n",
    "\n",
    "    callback = bkmod.callbacks.CustomJS(args=dict(slider = slider,source = source), code=f\"\"\"\n",
    "                //=========================================================\n",
    "                source.data['{x}:active'] = source.data['{x}:'+slider.value.toString()];\n",
    "                source.data['{y}:active'] = source.data['{y}:'+slider.value.toString()];\n",
    "                source.change.emit()\n",
    "                //=========================================================\"\"\")\n",
    "\n",
    "    slider.js_on_change('value', callback)\n",
    "    #=====================================\n",
    "\n",
    "\n",
    "    # Axis and Legend\n",
    "    #=====================================\n",
    "\n",
    "    fig.xaxis.axis_label = x\n",
    "    fig.yaxis.axis_label = y\n",
    "\n",
    "\n",
    "    #=====================================\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "BOKEH_FIGS['x-px'] = make_phasespace_fig(data.checkpoint_sig,xy=('x_sig','px_sig'),slider=chunk_slider,title='x norm. phase space',width=_default_fig_width//4,height=_default_fig_height)\n",
    "BOKEH_FIGS['y-py'] = make_phasespace_fig(data.checkpoint_sig,xy=('y_sig','py_sig'),slider=chunk_slider,title='y norm. phase space',width=_default_fig_width//4,height=_default_fig_height)\n",
    "BOKEH_FIGS['zeta-pzeta'] = make_phasespace_fig(data.checkpoint_sig,xy=('zeta_sig','pzeta_sig'),slider=chunk_slider,title='zeta norm. phase space',width=_default_fig_width//4,height=_default_fig_height)\n",
    "\n",
    "BOKEH_FIGS['x-y'] = make_phasespace_fig(data.checkpoint_sig,xy=('x_sig','y_sig'),slider=chunk_slider,title='Transverse norm space',width=_default_fig_width//4,height=_default_fig_height)\n",
    "\n",
    "\n",
    "bktools.set_aspect(BOKEH_FIGS['x-px']       , x_lim=(-6,6),y_lim=(-6,6), aspect=1, margin=0)\n",
    "bktools.set_aspect(BOKEH_FIGS['y-py']       , x_lim=(-6,6),y_lim=(-6,6), aspect=1, margin=0)\n",
    "bktools.set_aspect(BOKEH_FIGS['zeta-pzeta'] , x_lim=(-1,1),y_lim=(-1,1), aspect=1, margin=0)\n",
    "bktools.set_aspect(BOKEH_FIGS['x-y']        , x_lim=(-6,6),y_lim=(-6,6), aspect=1, margin=0)\n",
    "\n",
    "\n",
    "\n",
    "grid = bklay.gridplot([[BOKEH_FIGS['x-px'] ,BOKEH_FIGS['y-py'] ,BOKEH_FIGS['zeta-pzeta']],[BOKEH_FIGS['x-y'],chunk_slider]],toolbar_location='right')\n",
    "bk.show(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_df = data.data[['Chunk ID','start_at_turn','stop_at_turn']].groupby('Chunk ID').mean()\n",
    "# chunk_df.insert(0,'x',(chunk_df['stop_at_turn']+chunk_df['start_at_turn'])/2)\n",
    "\n",
    "xy = ('x','px')\n",
    "x,y = xy\n",
    "to_source = bktools.source_from_groupby(data.checkpoint,by='Chunk ID',columns = [x,y])\n",
    "to_source.insert(0,'particle',data.checkpoint.groupby('Chunk ID').get_group(0).particle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    chunk_df = data.data[['Chunk ID','start_at_turn','stop_at_turn']].groupby('Chunk ID').mean()\n",
    "\n",
    "    chunk_df.insert(0,'x',(chunk_df['stop_at_turn']+chunk_df['start_at_turn'])/2)\n",
    "\n",
    "\n",
    "    _df_list = []\n",
    "    for col in ['x']:\n",
    "        _df = pd.DataFrame({f'{_key}:{col}':_group[col].values for _key,_group in chunk_df.groupby('Chunk ID')})\n",
    "        _df_list.append(_df)\n",
    "\n",
    "    to_source = pd.concat(_df_list,axis=1)\n",
    "    for col in ['x'][::-1]:\n",
    "        to_source.insert(0,f'active:{col}',to_source[f'0:{col}'])\n",
    "    \n",
    "    to_source.insert(0,'width',(chunk_df['stop_at_turn']-chunk_df['start_at_turn']).max())\n",
    "    to_source.insert(1,'height',1)\n",
    "    to_source.insert(2,'y',0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction action\n",
    "J_df = data.checkpoint[['BUNCH','Chunk ID','turn','particle']]\n",
    "J_df.insert(4,'Jx/emitt',1/2 * (data.checkpoint_sig.x_sig**2 + data.checkpoint_sig.px_sig**2))\n",
    "J_df.insert(5,'Jy/emitt',1/2 * (data.checkpoint_sig.y_sig**2 + data.checkpoint_sig.py_sig**2))\n",
    "J_df.dropna(inplace=True)\n",
    "\n",
    "# Making Hextile grid\n",
    "J_min  = 0\n",
    "J_max  = 100\n",
    "n_bins = 300\n",
    "\n",
    "_size        = (J_max-J_min)/n_bins\n",
    "_orientation = 'pointytop'\n",
    "\n",
    "\n",
    "# Creating hextile template\n",
    "x_corners = [J_df['Jx/emitt'].min(),J_df['Jx/emitt'].max()]\n",
    "y_corners = [J_df['Jy/emitt'].min(),J_df['Jy/emitt'].max()]\n",
    "XX,YY    = np.meshgrid(np.arange(J_df['Jx/emitt'].min(),J_df['Jx/emitt'].max(),_size),\n",
    "                       np.arange(J_df['Jy/emitt'].min(),J_df['Jy/emitt'].max(),_size))\n",
    "hextiles_template = bkhex.hexbin(np.array(list(XX.flatten())+x_corners), np.array(list(YY.flatten())+y_corners), size=_size,orientation=_orientation)\n",
    "hextiles_template['counts']  = 0\n",
    "hextiles_template = hextiles_template.rename(columns={'counts':'counts:active'}).set_index(['q','r'])\n",
    "\n",
    "# Looping over chunks\n",
    "for name,group in J_df.groupby('Chunk ID'):\n",
    "    # Forcing corner values to have same grid.\n",
    "    _hex = bkhex.hexbin(np.array(list(group['Jx/emitt']) + [J_df['Jx/emitt'].min(),J_df['Jx/emitt'].max()]),\n",
    "                        np.array(list(group['Jy/emitt']) + [J_df['Jy/emitt'].min(),J_df['Jy/emitt'].max()]),\n",
    "                        size=_size,orientation=_orientation)\n",
    "\n",
    "    # Removing corner values\n",
    "    _hex = _hex[1:-1]\n",
    "\n",
    "    # Adding chunk ID\n",
    "    hextiles_template.insert(name+1,f'counts:{name}',_hex.set_index(['q','r'])['counts'])\n",
    "\n",
    "\n",
    "# setting empty bins to 0\n",
    "hextiles_template = hextiles_template.fillna(0).reset_index()\n",
    "hextiles_template['counts:active'] = hextiles_template['counts:0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hextiles_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating hextile template\n",
    "x_corners = [J_df['Jx/emitt'].min(),J_df['Jx/emitt'].max()]\n",
    "y_corners = [J_df['Jy/emitt'].min(),J_df['Jy/emitt'].max()]\n",
    "XX,YY    = np.meshgrid(np.arange(J_df['Jx/emitt'].min(),J_df['Jx/emitt'].max(),_size),\n",
    "                       np.arange(J_df['Jy/emitt'].min(),J_df['Jy/emitt'].max(),_size))\n",
    "hextiles_template = bkhex.hexbin(np.array(list(XX.flatten())+x_corners), np.array(list(YY.flatten())+y_corners), size=_size,orientation=_orientation)\n",
    "hextiles_template['counts']  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hextiles_template.rename(columns={'counts':'counts:active'}).set_index(['q','r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bktools.source_from_groupby(hextiles,by='Chunk ID',columns = ['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_df['Jx/emitt'].argmin(),J_df['Jx/emitt'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hex_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hex.iloc[[0,len(_hex)-1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "collection = plt.hexbin(group['Jx/emitt'],group['Jy/emitt'], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import rich\n",
    "rich.inspect(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_df = data.checkpoint[['BUNCH','Chunk ID','turn','particle']]\n",
    "J_df.insert(4,'Jx/emitt',1/2 * (data.checkpoint_sig.x_sig**2 + data.checkpoint_sig.px_sig**2))\n",
    "J_df.insert(5,'Jy/emitt',1/2 * (data.checkpoint_sig.y_sig**2 + data.checkpoint_sig.py_sig**2))\n",
    "J_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# coll_sig = np.max([data.sig_x_coll,data.sig_y_coll])\n",
    "coll_max = 10\n",
    "_x_dummy = np.linspace(0,10**2/2 ,300)\n",
    "\n",
    "\n",
    "_size        = np.min(np.abs(np.diff(_x_dummy)))\n",
    "_orientation = 'pointytop'\n",
    "\n",
    "hextiles = bkhex.hexbin(J_df['Jx/emitt'],J_df['Jy/emitt'], _size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hextiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df = data.data[['Chunk ID','start_at_turn','stop_at_turn']]\n",
    "chunk_df.insert(1,'width',chunk_df['stop_at_turn']-chunk_df['start_at_turn'])\n",
    "chunk_df.insert(2,'height',1)\n",
    "chunk_df.insert(3,'x',(chunk_df['stop_at_turn']+chunk_df['start_at_turn'])/2)\n",
    "chunk_df.insert(4,'y',0)\n",
    "chunk_df.groupby('Chunk ID').apply(lambda row: list(row['width']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df.groupby('Chunk ID')['width'].apply(lambda group : list(group)).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "460000*7,20000*23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunk_df = data.data[['Chunk ID','start_at_turn','stop_at_turn']].groupby('Chunk ID').mean()\n",
    "chunk_df.insert(1,'width',chunk_df['stop_at_turn']-chunk_df['start_at_turn'])\n",
    "chunk_df.insert(2,'height',1)\n",
    "chunk_df.insert(3,'x',(chunk_df['stop_at_turn']+chunk_df['start_at_turn'])/2)\n",
    "chunk_df.insert(4,'y',0)\n",
    "# chunk_df\n",
    "\n",
    "_df_list = []\n",
    "for col in ['x','width']:\n",
    "    _df = pd.DataFrame({f'{_key}:{col}':_group[col].values for _key,_group in chunk_df.groupby('Chunk ID')})\n",
    "    _df_list.append(_df)\n",
    "\n",
    "to_source = pd.concat(_df_list,axis=1)\n",
    "for col in ['x','width'][::-1]:\n",
    "    to_source.insert(0,f'active:{col}',to_source[f'0:{col}'])\n",
    "\n",
    "    \n",
    "source = bkto_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[(2,1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "{key:group for key,group in groups}[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data.checkpoint.state==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.checkpoint.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "test = coordinate_table(data.checkpoint,data.W_matrix,data.particle_on_co)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-BB",
   "language": "python",
   "name": "py-bb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
